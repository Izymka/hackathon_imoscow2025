# model/test_model.py
import torch
import os
import matplotlib.pyplot as plt
import seaborn as sns
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix, classification_report
from evaluate_model import evaluate_model, plot_roc_curve
from datasets.medical_tensors import MedicalTensorDataset
from monai.metrics import ConfusionMatrixMetric
from model_generator import generate_model
import argparse
import numpy as np


def create_test_config():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    config = argparse.Namespace()
    config.model = 'resnet'
    config.model_depth = 10  # –∏–∑–º–µ–Ω–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    config.n_seg_classes = 2  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
    config.no_cuda = not torch.cuda.is_available()
    config.input_D = 128
    config.input_H = 128
    config.input_W = 128
    config.resnet_shortcut = 'A'
    config.gpu_id = [] if config.no_cuda else [0]
    config.phase = 'test'
    config.pin_memory = not config.no_cuda
    config.pretrain_path = ''
    config.new_layer_names = ['fc']
    
    return config


def find_best_checkpoint(checkpoint_dirs):
    """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
    checkpoint_path = None
    
    for checkpoint_dir in checkpoint_dirs:
        if os.path.exists(checkpoint_dir):
            # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .pth –∏–ª–∏ .pth.tar
            checkpoints = [f for f in os.listdir(checkpoint_dir) 
                         if f.endswith('.pth') or f.endswith('.pth.tar')]
            if checkpoints:
                checkpoints.sort()
                checkpoint_path = os.path.join(checkpoint_dir, checkpoints[-1])
                print(f"–ù–∞–π–¥–µ–Ω —á–µ–∫–ø–æ–∏–Ω—Ç: {checkpoint_path}")
                break
    
    return checkpoint_path


def load_model_checkpoint(checkpoint_path, config, device):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model, _ = generate_model(config)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
    if 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –≤ –∫–ª—é—á–∞—Ö (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–±—É—á–∞–ª–∞—Å—å —Å DataParallel)
    from collections import OrderedDict
    new_state_dict = OrderedDict()
    for k, v in state_dict.items():
        if k.startswith('module.'):
            name = k[7:]  # —É–±–∏—Ä–∞–µ–º 'module.'
        else:
            name = k
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å—ë, —á—Ç–æ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ loss_fn
        if not name.startswith('loss_fn'):
            new_state_dict[name] = v
    
    model.load_state_dict(new_state_dict, strict=False)
    model = model.to(device)
    model.eval()
    
    return model


def plot_confusion_matrix_detailed(cm, class_names, output_dir):
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã –ø—É—Ç–∞–Ω–∏—Ü—ã"""
    plt.figure(figsize=(10, 8))
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –ø—É—Ç–∞–Ω–∏—Ü—ã
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    
    # –°–æ–∑–¥–∞–µ–º subplot'—ã
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names,
                ax=ax1, cbar_kws={'label': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª—É—á–∞–µ–≤'})
    ax1.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –ø—É—Ç–∞–Ω–∏—Ü—ã (–∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)')
    ax1.set_ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')
    ax1.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names,
                ax=ax2, cbar_kws={'label': '–î–æ–ª—è –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞'})
    ax2.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –ø—É—Ç–∞–Ω–∏—Ü—ã (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)')
    ax2.set_ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')
    ax2.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'detailed_confusion_matrix.png'), 
                dpi=300, bbox_inches='tight')
    plt.show()


def print_detailed_metrics(results, class_names):
    """–ü–µ—á–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
    print(f"\n{'=' * 60}")
    print("–î–ï–¢–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print(f"{'=' * 60}")
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    print(f"üìä –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {results['accuracy']:.4f} ({results['accuracy'] * 100:.2f}%)")
    print(f"üìà –°—Ä–µ–¥–Ω—è—è –ø–æ—Ç–µ—Ä—è: {results['loss']:.4f}")
    
    # –ê–Ω–∞–ª–∏–∑ –º–∞—Ç—Ä–∏—Ü—ã –ø—É—Ç–∞–Ω–∏—Ü—ã
    cm = results['confusion_matrix']
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –º–∞—Ç—Ä–∏—Ü—ã –ø—É—Ç–∞–Ω–∏—Ü—ã:")
    print(f"–ú–∞—Ç—Ä–∏—Ü–∞ –ø—É—Ç–∞–Ω–∏—Ü—ã:")
    for i, true_class in enumerate(class_names):
        for j, pred_class in enumerate(class_names):
            print(f"  {true_class} ‚Üí {pred_class}: {cm[i, j]}")
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç—å –∏ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if len(class_names) == 2:
        tn, fp, fn, tp = cm.ravel()
        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0
        npv = tn / (tn + fn) if (tn + fn) > 0 else 0
        
        print(f"\nü©∫ –ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏:")
        print(f"  –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (Sensitivity/Recall): {sensitivity:.4f} ({sensitivity * 100:.2f}%)")
        print(f"  –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç—å (Specificity): {specificity:.4f} ({specificity * 100:.2f}%)")
        print(f"  –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å (PPV): {ppv:.4f} ({ppv * 100:.2f}%)")
        print(f"  –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å (NPV): {npv:.4f} ({npv * 100:.2f}%)")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º
    print(f"\nüìã –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    print(classification_report(results['labels'], results['predictions'], 
                               target_names=class_names))


def main():
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üñ•Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –ü—É—Ç–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
    checkpoint_dirs = [
        'model/outputs/weights',
        'model/outputs/checkpoints',    # –Ω–æ–≤—ã–π –ø—É—Ç—å –∏–∑ config.py
        'trails/models/resnet_10',      # —Å—Ç–∞—Ä—ã–π –ø—É—Ç—å
        'outputs/checkpoints',          # –≤–æ–∑–º–æ–∂–Ω—ã–π –ø—É—Ç—å
        'checkpoints',                  # –µ—â–µ –æ–¥–∏–Ω –≤–æ–∑–º–æ–∂–Ω—ã–π –ø—É—Ç—å
    ]
    
    # –ü–æ–∏—Å–∫ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
    checkpoint_path = find_best_checkpoint(checkpoint_dirs)
    
    if not checkpoint_path:
        print("‚ùå –ß–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("üìÅ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
        for dir_path in checkpoint_dirs:
            print(f"   - {dir_path}")
        return
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = create_test_config()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = load_model_checkpoint(checkpoint_path, config, device)
    print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    
    # –ü—É—Ç–∏ –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫)
    test_data_paths = [
        ('data/test/tensors', 'data/test/labels.csv'),
        ('data/tensors', 'data/test_labels.csv'),
        ('../data/tensors', '../data/test_labels.csv'),
        ('data/processed', 'data/processed/labels.csv'),
    ]
    
    # –ü–æ–∏—Å–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    test_data_root = None
    test_labels_path = None
    
    for data_root, labels_path in test_data_paths:
        if os.path.exists(data_root) and os.path.exists(labels_path):
            test_data_root = data_root
            test_labels_path = labels_path
            break
    
    if not test_data_root:
        print("‚ùå –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print("üìÅ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –ø—É—Ç–∏:")
        for data_root, labels_path in test_data_paths:
            print(f"   - –î–∞–Ω–Ω—ã–µ: {data_root}, –ú–µ—Ç–∫–∏: {labels_path}")
        return
    
    print(f"üìÇ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print(f"   - –î–∞–Ω–Ω—ã–µ: {test_data_root}")
    print(f"   - –ú–µ—Ç–∫–∏: {test_labels_path}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    print("üìä –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    test_dataset = MedicalTensorDataset(
        data_root=test_data_root,
        img_list=test_labels_path,
        sets=config
    )
    
    print(f"üìà –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(test_dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # DataLoader
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_dir = 'test_results'
    os.makedirs(output_dir, exist_ok=True)
    
    # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
    print("üîÑ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")
    class_names = ['–ó–¥–æ—Ä–æ–≤', '–ë–æ–ª–µ–Ω']  # –∏–∑–º–µ–Ω–∏ –ø–æ–¥ —Å–≤–æ–∏ –∫–ª–∞—Å—Å—ã
    
    results = evaluate_model(
        model=model,
        test_loader=test_loader,
        device=device,
        class_names=class_names,
        save_results=True,
        output_dir=output_dir
    )
    
    # –ü–µ—á–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
    print_detailed_metrics(results, class_names)
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã –ø—É—Ç–∞–Ω–∏—Ü—ã
    plot_confusion_matrix_detailed(results['confusion_matrix'], class_names, output_dir)
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ ROC-–∫—Ä–∏–≤–æ–π (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
    if 'probabilities' in results:
        plot_roc_curve(results['labels'], results['probabilities'], class_names, output_dir)
    
    print(f"\nüíæ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {output_dir}")
    print("üìã –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print("   - evaluation_metrics.txt - —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏")
    print("   - confusion_matrix.png - –º–∞—Ç—Ä–∏—Ü–∞ –ø—É—Ç–∞–Ω–∏—Ü—ã")
    print("   - detailed_confusion_matrix.png - –¥–µ—Ç–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –ø—É—Ç–∞–Ω–∏—Ü—ã")
    print("   - predictions.csv - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞")
    if 'probabilities' in results:
        print("   - roc_curve.png - ROC-–∫—Ä–∏–≤–∞—è")
    
    print(f"\nüéØ –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {results['accuracy']*100:.2f}% —Ç–æ—á–Ω–æ—Å—Ç–∏")


if __name__ == "__main__":
    main()