import torch
from torch import nn
from models import resnet


def adapt_first_conv_layer_to_4ch(model, pretrained_state_dict=None):
    """
    –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –ø–µ—Ä–≤—ã–π —Å–≤—ë—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π –º–æ–¥–µ–ª–∏ –ø–æ–¥ 4-–∫–∞–Ω–∞–ª—å–Ω—ã–π –≤—Ö–æ–¥.

    Args:
        model: –∏—Å—Ö–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å —Å 1-–∫–∞–Ω–∞–ª—å–Ω—ã–º conv1
        pretrained_state_dict: —Å–ª–æ–≤–∞—Ä—å –≤–µ—Å–æ–≤ MedicalNet (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        –º–æ–¥–µ–ª—å —Å conv1 –Ω–∞ 4 –∫–∞–Ω–∞–ª–∞
    """
    device = next(model.parameters()).device

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞, –µ—Å–ª–∏ –µ—Å—Ç—å
    if pretrained_state_dict is not None:
        # –£–±–∏—Ä–∞–µ–º 'module.' –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        cleaned_state_dict = {}
        for k, v in pretrained_state_dict.items():
            new_k = k.replace('module.', '') if k.startswith('module.') else k
            cleaned_state_dict[new_k] = v
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å strict=False, —Ç–∞–∫ –∫–∞–∫ conv1 –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
        model.load_state_dict(cleaned_state_dict, strict=False)

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ—Å conv1 (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å [C_out, 1, K, K, K])
    original_weight = model.conv1.weight.data  # [64, 1, 7, 7, 7] –¥–ª—è ResNet-18/34
    assert original_weight.shape[1] == 1, f"–û–∂–∏–¥–∞–ª—Å—è 1 –≤—Ö–æ–¥–Ω–æ–π –∫–∞–Ω–∞–ª, –ø–æ–ª—É—á–µ–Ω–æ {original_weight.shape[1]}"

    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π –≤–µ—Å: –ø–æ–≤—Ç–æ—Ä—è–µ–º –∏ –¥–µ–ª–∏–º –Ω–∞ 4 –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–∞—Å—à—Ç–∞–±–∞
    new_weight = original_weight.repeat(1, 4, 1, 1, 1) / 4.0  # [64, 4, 7, 7, 7]

    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π conv1 —Å–ª–æ–π
    new_conv1 = nn.Conv3d(
        in_channels=4,
        out_channels=original_weight.shape[0],
        kernel_size=model.conv1.kernel_size,
        stride=model.conv1.stride,
        padding=model.conv1.padding,
        bias=model.conv1.bias is not None
    )
    new_conv1.weight.data = new_weight
    if new_conv1.bias is not None:
        new_conv1.bias.data = model.conv1.bias.data.clone()

    # –ó–∞–º–µ–Ω—è–µ–º –≤ –º–æ–¥–µ–ª–∏
    model.conv1 = new_conv1.to(device)
    print(f"‚úÖ –ó–∞–º–µ–Ω—ë–Ω conv1: {original_weight.shape} ‚Üí {new_weight.shape}")
    return model


def adapt_model_for_input_size_and_channels(model, input_size, model_depth, n_seg_classes, n_input_channels=4):
    """
    –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –ø–æ–¥ –Ω–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ –ò –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤.
    """
    print(f"üîß –ê–¥–∞–ø—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Ö–æ–¥–∞ {n_input_channels}x{input_size}...")

    device = next(model.parameters()).device

    # === 1. –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è –ø–æ–¥ 4 –∫–∞–Ω–∞–ª–∞ ===
    if n_input_channels != 1:
        model = adapt_first_conv_layer_to_4ch(model)  # –≤–µ—Å–∞ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —Ä–∞–Ω–µ–µ

    # === 2. –ó–∞–º–æ—Ä–æ–∑–∫–∞ –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ===
    for param in model.parameters():
        param.requires_grad = False

    # === 3. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ FC —Å–ª–æ—è ===
    with torch.no_grad():
        dummy_input = torch.randn(1, n_input_channels, input_size[2], input_size[1], input_size[0]).to(device)

        # –°–æ–±–∏—Ä–∞–µ–º —Å–≤—ë—Ä—Ç–æ—á–Ω—É—é —á–∞—Å—Ç—å
        if hasattr(model, 'module'):
            conv_seq = nn.Sequential(
                model.module.conv1,
                model.module.bn1,
                model.module.relu,
                model.module.maxpool,
                model.module.layer1,
                model.module.layer2,
                model.module.layer3,
                model.module.layer4,
                model.module.avgpool
            )
        else:
            conv_seq = nn.Sequential(
                model.conv1,
                model.bn1,
                model.relu,
                model.maxpool,
                model.layer1,
                model.layer2,
                model.layer3,
                model.layer4,
                model.avgpool
            )
        conv_seq = conv_seq.to(device)
        conv_out = conv_seq(dummy_input)
        flattened_size = conv_out.view(conv_out.size(0), -1).size(1)

    print(f"üìä –†–∞–∑–º–µ—Ä FC –≤—Ö–æ–¥–∞: {flattened_size}")

    # === 4. –ó–∞–º–µ–Ω–∞ FC —Å–ª–æ—è ===
    if hasattr(model, 'module'):
        old_fc = model.module.fc
        model.module.fc = nn.Linear(flattened_size, n_seg_classes).to(device)
        new_fc = model.module.fc
    else:
        old_fc = model.fc
        model.fc = nn.Linear(flattened_size, n_seg_classes).to(device)
        new_fc = model.fc

    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–æ–≤—ã–π FC —Å–ª–æ–π –Ω–∞ —Ç–æ –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    if hasattr(model, 'module'):
        model.module.fc = model.module.fc.to(device)
    else:
        model.fc = model.fc.to(device)

    print(f"üîÑ –ó–∞–º–µ–Ω–µ–Ω FC —Å–ª–æ–π: {old_fc.in_features} ‚Üí {flattened_size} –≤—Ö–æ–¥–æ–≤, {n_seg_classes} –≤—ã—Ö–æ–¥–æ–≤")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ —Å–ª–æ—è
    if isinstance(new_fc, nn.Linear):
        nn.init.xavier_uniform_(new_fc.weight)
        if new_fc.bias is not None:
            nn.init.zeros_(new_fc.bias)

    print(f"üîÑ FC —Å–ª–æ–π: {old_fc.in_features} ‚Üí {flattened_size} –≤—Ö–æ–¥–æ–≤, {n_seg_classes} –≤—ã—Ö–æ–¥–æ–≤")

    # === 5. –†–∞–∑–º–æ—Ä–æ–∑–∫–∞ –Ω—É–∂–Ω—ã—Ö —Å–ª–æ—ë–≤ ===
    layers_to_unfreeze = ['layer3', 'layer4', 'fc']
    print("üî• –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ —Å–ª–æ—ë–≤:", layers_to_unfreeze)

    def unfreeze_module(module):
        for name, child in module.named_children():
            if name in ['layer3', 'layer4']:
                for param in child.parameters():
                    param.requires_grad = True
            elif name == 'fc':
                for param in child.parameters():
                    param.requires_grad = True

    if hasattr(model, 'module'):
        unfreeze_module(model.module)
    else:
        unfreeze_module(model)

    # –°–æ–±–∏—Ä–∞–µ–º –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    trainable_params = [p for p in model.parameters() if p.requires_grad]
    print(f"üìà –û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {sum(p.numel() for p in trainable_params)}")

    return model, trainable_params


def generate_model(opt):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 4-–∫–∞–Ω–∞–ª—å–Ω–æ–≥–æ –≤—Ö–æ–¥–∞ –∏ transfer learning –æ—Ç MedicalNet.
    """
    assert opt.model in ['resnet']
    assert opt.model_depth in [10, 18, 34, 50, 101, 152, 200]

    # === 1. –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ ===
    model_functions = {
        10: resnet.resnet10,
        18: resnet.resnet18,
        34: resnet.resnet34,
        50: resnet.resnet50,
        101: resnet.resnet101,
        152: resnet.resnet152,
        200: resnet.resnet200
    }

    # –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å —Å 1 –∫–∞–Ω–∞–ª–æ–º (MedicalNet —Å—Ç–∞–Ω–¥–∞—Ä—Ç)
    model = model_functions[opt.model_depth](
        sample_input_W=opt.input_W,
        sample_input_H=opt.input_H,
        sample_input_D=opt.input_D,
        shortcut_type=opt.resnet_shortcut,
        no_cuda=opt.no_cuda,
        num_seg_classes=opt.n_seg_classes
    )

    # === 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ ===
    if not opt.no_cuda and torch.cuda.is_available():
        model = model.cuda()
        if len(opt.gpu_id) > 1:
            model = nn.DataParallel(model, device_ids=opt.gpu_id)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω GPU
            torch.cuda.set_device(opt.gpu_id[0])
    # –ò–Ω–∞—á–µ –æ—Å—Ç–∞—ë—Ç—Å—è –Ω–∞ CPU

    # === 3. –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤ ===
    pretrained_state_dict = None
    if opt.phase != 'test' and opt.pretrain_path:
        print(f'üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {opt.pretrain_path}')
        map_location = torch.device('cpu') if opt.no_cuda or not torch.cuda.is_available() else None
        checkpoint = torch.load(opt.pretrain_path, map_location=map_location, weights_only=True)

        # MedicalNet —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–µ—Å–∞ –≤ 'state_dict'
        if 'state_dict' in checkpoint:
            pretrained_state_dict = checkpoint['state_dict']
        else:
            pretrained_state_dict = checkpoint  # –Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –Ω–∞–ø—Ä—è–º—É—é

    # === 4. –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ 4 –∫–∞–Ω–∞–ª–∞ –∏ —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ ===
    current_input_size = (opt.input_W, opt.input_H, opt.input_D)
    n_input_channels = getattr(opt, 'n_input_channels', 4)  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 4

    # –í—Å–µ–≥–¥–∞ –∞–¥–∞–ø—Ç–∏—Ä—É–µ–º, —Ç–∞–∫ –∫–∞–∫ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º 4 –∫–∞–Ω–∞–ª–∞
    model, trainable_params = adapt_model_for_input_size_and_channels(
        model=model,
        input_size=current_input_size,
        model_depth=opt.model_depth,
        n_seg_classes=opt.n_seg_classes,
        n_input_channels=n_input_channels
    )

    return model, trainable_params