# production_example.py
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ.
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è inference –∫–ª–∞—Å—Å–∞.
"""

import torch
import numpy as np
from pathlib import Path
import time
from inference import MedicalModelInference
from config import ModelConfig


class ProductionPipeline:
    """–ü—Ä–∏–º–µ—Ä production pipeline –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏."""
    
    def __init__(self, weights_path: str, config: ModelConfig = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è production pipeline.
        
        Args:
            weights_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        """
        self.inference = MedicalModelInference(weights_path, config)
        self.processing_times = []
        
    def preprocess_data(self, raw_data: np.ndarray) -> torch.Tensor:
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            raw_data: –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ DICOM —Ñ–∞–π–ª–∞)
            
        Returns:
            torch.Tensor: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä
        """
        # –ó–¥–µ—Å—å –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–∞—à–∞ –ª–æ–≥–∏–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏:
        # - –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        # - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞
        # - —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —à—É–º–æ–≤ –∏ —Ç.–¥.
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        data = raw_data.astype(np.float32)
        data = (data - data.mean()) / data.std()
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
        if data.shape != (128, 128, 128):
            # –ó–¥–µ—Å—å –º–æ–∂–µ—Ç –±—ã—Ç—å resize –ª–æ–≥–∏–∫–∞
            print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö {data.shape} –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É (128, 128, 128)")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º–∏
        tensor = torch.from_numpy(data).unsqueeze(0).unsqueeze(0)  # [1, 1, D, H, W]
        
        return tensor
    
    def process_single_case(self, raw_data: np.ndarray, case_id: str = None) -> dict:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–ª—É—á–∞—è.
        
        Args:
            raw_data: –°—ã—Ä—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            case_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–ª—É—á–∞—è
            
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        start_time = time.time()
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        tensor = self.preprocess_data(raw_data)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction = self.inference.predict(tensor)
        
        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        processing_time = time.time() - start_time
        self.processing_times.append(processing_time)
        
        result = {
            'case_id': case_id,
            'diagnosis': prediction['predicted_class_name'],
            'confidence': prediction['confidence'],
            'probabilities': {
                'healthy': prediction['probabilities'][0],
                'pathology': prediction['probabilities'][1]
            },
            'processing_time_seconds': processing_time,
            'recommendation': self._generate_recommendation(prediction)
        }
        
        return result
    
    def process_batch_cases(self, raw_data_list: list, case_ids: list = None) -> list:
        """
        –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤.
        
        Args:
            raw_data_list: –°–ø–∏—Å–æ–∫ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            case_ids: –°–ø–∏—Å–æ–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å–ª—É—á–∞–µ–≤
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        """
        if case_ids is None:
            case_ids = [f"case_{i+1}" for i in range(len(raw_data_list))]
        
        start_time = time.time()
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Å–ª—É—á–∞–µ–≤
        tensors = []
        for raw_data in raw_data_list:
            tensor = self.preprocess_data(raw_data)
            tensors.append(tensor.squeeze(0))  # —É–±–∏—Ä–∞–µ–º batch dimension –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω –±–∞—Ç—á
        batch_tensor = torch.stack(tensors)  # [N, 1, D, H, W]
        
        # –ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        predictions = self.inference.predict_batch(batch_tensor)
        
        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        total_time = time.time() - start_time
        avg_time_per_case = total_time / len(raw_data_list)
        
        results = []
        for i, (case_id, prediction) in enumerate(zip(case_ids, predictions)):
            result = {
                'case_id': case_id,
                'diagnosis': prediction['predicted_class_name'],
                'confidence': prediction['confidence'],
                'probabilities': {
                    'healthy': prediction['probabilities'][0],
                    'pathology': prediction['probabilities'][1]
                },
                'processing_time_seconds': avg_time_per_case,
                'recommendation': self._generate_recommendation(prediction)
            }
            results.append(result)
        
        return results
    
    def _generate_recommendation(self, prediction: dict) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
        
        Args:
            prediction: –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
            
        Returns:
            str: –¢–µ–∫—Å—Ç–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        """
        confidence = prediction['confidence']
        predicted_class = prediction['predicted_class']
        
        if predicted_class == 0:  # –ó–¥–æ—Ä–æ–≤
            if confidence > 0.9:
                return "–í—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø–∞—Ç–æ–ª–æ–≥–∏–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ."
            elif confidence > 0.7:
                return "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø–∞—Ç–æ–ª–æ–≥–∏–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–µ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ 6 –º–µ—Å—è—Ü–µ–≤."
            else:
                return "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞."
        else:  # –ë–æ–ª–µ–Ω
            if confidence > 0.9:
                return "–í—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–∞—Ç–æ–ª–æ–≥–∏–∏. –¢—Ä–µ–±—É–µ—Ç—Å—è —Å—Ä–æ—á–Ω–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è."
            elif confidence > 0.7:
                return "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–∞—Ç–æ–ª–æ–≥–∏–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è."
            else:
                return "–ü–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ç–æ–ª–æ–≥–∏—é. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞."
    
    def get_performance_stats(self) -> dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        if not self.processing_times:
            return {"message": "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –Ω–µ –±—ã–ª–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"}
        
        return {
            "total_processed": len(self.processing_times),
            "average_time_seconds": np.mean(self.processing_times),
            "min_time_seconds": np.min(self.processing_times),
            "max_time_seconds": np.max(self.processing_times),
            "cases_per_minute": 60 / np.mean(self.processing_times)
        }


def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ."""
    print("üè• –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è Production Pipeline –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
    print("=" * 70)
    
    # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏ (–∏–∑–º–µ–Ω–∏—Ç–µ –ø–æ–¥ —Å–≤–æ–∏ –ø—É—Ç–∏)
    weights_path = "model/outputs/checkpoints/best_weights.pth"
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pipeline
        pipeline = ProductionPipeline(weights_path)
        
        print("‚úÖ Pipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ!")
        
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–ª—É—á–∞—è
        print("\nüìã –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–ª—É—á–∞—è")
        print("-" * 50)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–æ –±—É–¥—É—Ç –≤–∞—à–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ)
        test_data = np.random.randn(128, 128, 128).astype(np.float32)
        
        result = pipeline.process_single_case(test_data, case_id="PATIENT_001")
        
        print(f"üè• –°–ª—É—á–∞–π: {result['case_id']}")
        print(f"üî¨ –î–∏–∞–≥–Ω–æ–∑: {result['diagnosis']}")
        print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.2%}")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result['processing_time_seconds']:.3f} —Å–µ–∫")
        print(f"üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {result['recommendation']}")
        
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 2: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        print("\nüì¶ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 2: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞")
        print("-" * 50)
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–ª—É—á–∞–µ–≤
        batch_data = [np.random.randn(128, 128, 128).astype(np.float32) for _ in range(3)]
        case_ids = ["PATIENT_002", "PATIENT_003", "PATIENT_004"]
        
        batch_results = pipeline.process_batch_cases(batch_data, case_ids)
        
        for result in batch_results:
            print(f"üè• {result['case_id']}: {result['diagnosis']} "
                  f"({result['confidence']:.2%} —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏)")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        print("-" * 50)
        
        stats = pipeline.get_performance_stats()
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"{key}: {value:.4f}")
            else:
                print(f"{key}: {value}")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        print("\nü§ñ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")
        print("-" * 50)
        
        model_info = pipeline.inference.get_model_info()
        for key, value in model_info.items():
            print(f"{key}: {value}")
    
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª –≤–µ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print(f"üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {weights_path}")
        print("üí° –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å —Å–Ω–∞—á–∞–ª–∞, –∑–∞–ø—É—Å—Ç–∏–≤: python main.py")
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()
