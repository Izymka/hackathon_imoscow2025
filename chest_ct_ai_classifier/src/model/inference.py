import torch
import torch.nn.functional as F
import numpy as np
from typing import Union, List, Dict, Optional
from pathlib import Path
from omegaconf import OmegaConf
import warnings
import os
import gc

os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# –ó–∞–º–µ–Ω—è–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
try:
    from .model_generator import generate_model
    from .lightning_module import MedicalClassificationModel
except ImportError:
    # –ï—Å–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π
    from model_generator import generate_model
    from lightning_module import MedicalClassificationModel


# –î–æ–±–∞–≤–ª—è–µ–º Captum
try:
    from captum.attr import IntegratedGradients, Saliency, LayerGradCam, LayerAttribution
    from captum.attr import visualization as viz
    import matplotlib.pyplot as plt
    from matplotlib.colors import LinearSegmentedColormap

    CAPTUM_AVAILABLE = True
except ImportError:
    CAPTUM_AVAILABLE = False
    print("‚ö†Ô∏è Captum –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install captum")

warnings.filterwarnings("ignore", category=UserWarning)


class MedicalModelInference:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.

    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç 3D —Ç–µ–Ω–∑–æ—Ä —Ä–∞–∑–º–µ—Ä–æ–º 256x256x256 –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ.
    """

    def __init__(self,
                 weights_path: str,
                 model_config: 'ModelConfig',  # –ò–∑–º–µ–Ω–∏–ª–∏ —Ç–∏–ø –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                 device: Optional[str] = None,
                 use_half_precision: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è inference –º–æ–¥—É–ª—è.

        Args:
            weights_path: –ø—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É –º–æ–¥–µ–ª–∏
            model_config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (ModelConfig)
            device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ('cuda' –∏–ª–∏ 'cpu'), –µ—Å–ª–∏ None - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            use_half_precision: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ half precision (float16) –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        """
        self.weights_path = Path(weights_path)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ModelConfig –≤ OmegaConf
        if isinstance(model_config, dict):
            self.model_config = OmegaConf.create(model_config)
        elif hasattr(model_config, '__dict__'):  # –≠—Ç–æ ModelConfig (dataclass)
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º dataclass –≤ —Å–ª–æ–≤–∞—Ä—å, –∑–∞—Ç–µ–º –≤ OmegaConf
            config_dict = {}
            for field_name in dir(model_config):
                if not field_name.startswith('_'):
                    try:
                        value = getattr(model_config, field_name)
                        if not callable(value):
                            config_dict[field_name] = value
                    except:
                        continue
            self.model_config = OmegaConf.create(config_dict)
        else:
            self.model_config = model_config if isinstance(model_config, OmegaConf) else OmegaConf.create(model_config)

        self.use_half_precision = use_half_precision

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device

        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.model = self._load_model()
        self.model.eval()

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ half precision –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.use_half_precision and self.device == 'cuda':
            self.model.half()
            self._half_precision = True
        else:
            self._half_precision = False

        print(f"‚úÖ Inference –º–æ–¥—É–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")
        print(f"üìä –û–∂–∏–¥–∞–µ–º—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: 1, 1, 256, 256, 256")
        print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {self.model_config.n_seg_classes}")

    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å —É—Å—Ç–æ–π—á–∏–≤–æ–π –ø–æ–¥–≥–æ–Ω–∫–æ–π –∫–ª—é—á–µ–π state_dict."""
        config_dict = OmegaConf.to_container(self.model_config)
        config_dict['gpu_id'] = [0] if torch.cuda.is_available() else []
        config_dict['phase'] = 'test'
        config_dict['no_cuda'] = (self.device == 'cpu')

        from argparse import Namespace
        args = Namespace(**config_dict)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—Å—Ç—É—é –º–æ–¥–µ–ª—å —Ü–µ–ª–µ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        model, _ = generate_model(args)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç (CPU-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ)
        checkpoint = torch.load(self.weights_path, map_location=('cpu' if self.device == 'cpu' else self.device), weights_only=False)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π state_dict –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
        raw_sd = None
        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint and isinstance(checkpoint['state_dict'], dict):
            raw_sd = checkpoint['state_dict']
        elif isinstance(checkpoint, dict):
            # –ï—Å–ª–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ –º–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–æ–≤ ‚Äî —ç—Ç–æ, –≤–µ—Ä–æ—è—Ç–Ω–æ, —Å–∞–º state_dict
            tensor_like = [k for k, v in checkpoint.items() if isinstance(v, torch.Tensor)]
            if len(tensor_like) > 0:
                raw_sd = checkpoint
        # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω, –ø—Ä–æ–±—É–µ–º –Ω–∞–ø—Ä—è–º—É—é –∫–∞–∫ state_dict
        if raw_sd is None:
            raw_sd = checkpoint if isinstance(checkpoint, dict) else {}

        target_sd = model.state_dict()

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–ª—é—á–∏: —É–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã 'model.module.', 'module.', 'model.'
        def normalize_key(k: str) -> str:
            for pref in ('model.module.', 'module.', 'model.'):
                if k.startswith(pref):
                    k = k[len(pref):]
            return k

        cleaned_sd = {}
        matched, total = 0, 0
        for k, v in raw_sd.items():
            total += 1
            nk = normalize_key(k)
            if nk in target_sd and target_sd[nk].shape == v.shape:
                cleaned_sd[nk] = v
                matched += 1

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é –ø–æ–¥–º–Ω–æ–∂–∏–Ω—É –≤–µ—Å–æ–≤
        missing, unexpected = model.load_state_dict(cleaned_sd, strict=False)
        try:
            print(f"üîë –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤: —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ {matched}/{total}; –ø—Ä–æ–ø—É—â–µ–Ω–æ {len(missing)}; –ª–∏—à–Ω–∏—Ö {len(unexpected)}")
        except Exception:
            pass

        # –£–±–∏—Ä–∞–µ–º DataParallel, –µ—Å–ª–∏ –µ—Å—Ç—å
        if hasattr(model, 'module'):
            model = model.module

        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        model = model.to(self.device)
        model.eval()
        return model

    def _validate_input_tensor(self, tensor: torch.Tensor) -> torch.Tensor:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞."""
        if not isinstance(tensor, torch.Tensor):
            raise TypeError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è torch.Tensor, –ø–æ–ª—É—á–µ–Ω–æ {type(tensor)}")

        if tensor.dim() != 5:
            raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è 5D —Ç–µ–Ω–∑–æ—Ä (B, C, D, H, W), –ø–æ–ª—É—á–µ–Ω–æ {tensor.shape}")

        batch_size, channels, depth, height, width = tensor.shape

        expected_shape = (1, 1, 256, 256, 256)
        if (channels, depth, height, width) != expected_shape[1:]:
            raise ValueError(
                f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã {expected_shape}, "
                f"–ø–æ–ª—É—á–µ–Ω–æ {tensor.shape}. "
                f"–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–∞–∑–º–µ—Ä—ã: channels=1, depth=256, height=256, width=256"
            )

        tensor = tensor.to(self.device)

        if self._half_precision:
            tensor = tensor.half()
        else:
            tensor = tensor.float()

        return tensor

    def _free_memory(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ GPU –∏ —Å–±–æ—Ä –º—É—Å–æ—Ä–∞."""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    def predict(self, input_tensor: torch.Tensor) -> Dict[str, Union[float, int, np.ndarray]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º —Ç–µ–Ω–∑–æ—Ä–µ."""
        with torch.no_grad():
            input_tensor = self._validate_input_tensor(input_tensor)

            if self._half_precision:
                with torch.cuda.amp.autocast():
                    logits = self.model(input_tensor)
            else:
                logits = self.model(input_tensor)

            probabilities = F.softmax(logits, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1).item()
            confidence = torch.max(probabilities, dim=1)[0].item()

            logits_np = logits.cpu().numpy()
            probabilities_np = probabilities.cpu().numpy()

            # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            self._free_memory()

            return {
                'prediction': int(predicted_class),
                'probabilities': probabilities_np.squeeze(),
                'confidence': float(confidence),
                'logits': logits_np.squeeze()
            }

    def explain_prediction(self, input_tensor: torch.Tensor, target_class: Optional[int] = None,
                           method: str = "saliency", visualize: bool = True,
                           threshold: float = 0.1, alpha: float = 0.7):
        """
        –û–±—ä—è—Å–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Captum.

        Args:
            input_tensor: —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã (1, 1, 256, 256, 256)
            target_class: –∫–ª–∞—Å—Å –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π)
            method: –º–µ—Ç–æ–¥ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è ('integrated_gradients', 'saliency')
            visualize: –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
            threshold: –ø–æ—Ä–æ–≥ –¥–ª—è –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–∞–±—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ (0-1)
            alpha: –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –Ω–∞–ª–æ–∂–µ–Ω–∏—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã

        Returns:
            attributions: –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ (—Ç–µ–Ω–∑–æ—Ä —Å —Ç–µ–º –∂–µ —Ä–∞–∑–º–µ—Ä–æ–º, —á—Ç–æ –∏ –≤—Ö–æ–¥)
        """
        if not CAPTUM_AVAILABLE:
            raise ImportError("Captum –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install captum")

        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
            original_tensor = input_tensor.clone()
            input_tensor = self._validate_input_tensor(input_tensor)

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            prediction_result = self.predict(original_tensor)
            if target_class is None:
                target_class = prediction_result['prediction']

            print(f"üéØ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∞ {target_class} —Å –º–µ—Ç–æ–¥–æ–º {method}")

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–Ω–∑–æ—Ä –¥–ª—è –∞—Ç—Ä–∏–±—É—Ü–∏–∏
            input_tensor = input_tensor.detach()
            input_tensor.requires_grad_(False)

            # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            self._free_memory()

            # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏
            if method == "integrated_gradients":
                explainer = IntegratedGradients(self.model)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–µ —à–∞–≥–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                with torch.no_grad():
                    attributions = explainer.attribute(input_tensor, target=target_class, n_steps=15)
            elif method == "saliency":
                explainer = Saliency(self.model)
                with torch.no_grad():
                    attributions = explainer.attribute(input_tensor, target=target_class, abs=False)
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –º–µ—Ç–æ–¥: {method}")

            if visualize:
                self._visualize_3d_attributions_enhanced(
                    attributions, original_tensor,
                    title=f"Attributions ({method})",
                    threshold=threshold,
                    alpha=alpha
                )

            return attributions

        except RuntimeError as e:
            if "out of memory" in str(e):
                print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ GPU –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
                print("   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å method='saliency'")
                print("   - –£–≤–µ–ª–∏—á–∏—Ç—å threshold (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.3)")
                print("   - –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ CPU")
                self._free_memory()
                return None
            else:
                raise e

    def _visualize_3d_attributions_enhanced(self, attributions, original_tensor,
                                            title="Attributions", threshold=0.1, alpha=0.7):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ–º –Ω—É–ª–µ–π –∏ –Ω–∞–ª–æ–∂–µ–Ω–∏–µ–º."""
        attr_np = attributions.squeeze().detach().cpu().numpy()
        original_np = original_tensor.squeeze().detach().cpu().numpy()

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        original_normalized = (original_np - original_np.min()) / (original_np.max() - original_np.min())

        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –∑–Ω–∞—á–∏–º—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤
        attr_abs = np.abs(attr_np)
        attr_max = np.max(attr_abs)

        if attr_max > 0:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
            attr_normalized = attr_abs / attr_max
            mask = attr_normalized > threshold
        else:
            mask = np.zeros_like(attr_abs, dtype=bool)

        mid_slice = attr_np.shape[0] // 2

        # –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é colormap —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é –¥–ª—è –Ω–∏–∑–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        colors = plt.cm.hot(np.linspace(0, 1, 256))
        colors[0] = [0, 0, 0, 0]  # –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
        transparent_hot = LinearSegmentedColormap.from_list('transparent_hot', colors)

        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç—Ä–µ—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π
        planes = [
            ('Axial (Z)', mid_slice, lambda x: x[mid_slice, :, :]),
            ('Coronal (Y)', mid_slice, lambda x: x[:, mid_slice, :]),
            ('Sagittal (X)', mid_slice, lambda x: x[:, :, mid_slice])
        ]

        for i, (plane_name, slice_idx, slice_fn) in enumerate(planes):
            # –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            orig_slice = slice_fn(original_normalized)
            axes[0, i].imshow(orig_slice, cmap='gray', vmin=0, vmax=1)
            axes[0, i].set_title(f"{plane_name} - –ò—Å—Ö–æ–¥–Ω–æ–µ")
            axes[0, i].axis('off')

            # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å –Ω–∞–ª–æ–∂–µ–Ω–∏–µ–º
            attr_slice = slice_fn(attr_np)
            mask_slice = slice_fn(mask)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
            masked_attr = np.ma.masked_where(~mask_slice, attr_slice)

            im = axes[1, i].imshow(orig_slice, cmap='gray', vmin=0, vmax=1)
            im2 = axes[1, i].imshow(masked_attr, cmap=transparent_hot,
                                    alpha=alpha, vmin=attr_np.min(), vmax=attr_np.max())

            axes[1, i].set_title(f"{plane_name} - –ê—Ç—Ä–∏–±—É—Ç—ã (–ø–æ—Ä–æ–≥: {threshold})")
            axes[1, i].axis('off')

            # –î–æ–±–∞–≤–ª—è–µ–º colorbar –¥–ª—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            plt.colorbar(im2, ax=axes[1, i], fraction=0.046, pad=0.04)

        plt.suptitle(f"{title}\n(–ø–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ –∞—Ç—Ä–∏–±—É—Ç—ã > {threshold:.1%} –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞)", fontsize=14)
        plt.tight_layout()
        plt.show()

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        total_voxels = np.prod(attr_np.shape)
        significant_voxels = np.sum(mask)
        print(f"üìä –ó–Ω–∞—á–∏–º—ã–µ –≤–æ–∫—Å–µ–ª–∏: {significant_voxels}/{total_voxels} ({significant_voxels / total_voxels:.1%})")
        print(f"üìà –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç: {attr_np.max():.4f}, –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π: {attr_np.min():.4f}")

    def _visualize_3d_attributions(self, attributions, title="Attributions"):
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –ø–æ –æ—Å—è–º (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)."""
        attr_np = attributions.squeeze().detach().cpu().numpy()

        mid_slice = attr_np.shape[0] // 2

        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # Axial (Z)
        im1 = axes[0].imshow(attr_np[mid_slice, :, :], cmap='hot', vmin=attr_np.min(), vmax=attr_np.max())
        axes[0].set_title("Axial (Z)")
        plt.colorbar(im1, ax=axes[0])

        # Coronal (Y)
        im2 = axes[1].imshow(attr_np[:, mid_slice, :], cmap='hot', vmin=attr_np.min(), vmax=attr_np.max())
        axes[1].set_title("Coronal (Y)")
        plt.colorbar(im2, ax=axes[1])

        # Sagittal (X)
        im3 = axes[2].imshow(attr_np[:, :, mid_slice], cmap='hot', vmin=attr_np.min(), vmax=attr_np.max())
        axes[2].set_title("Sagittal (X)")
        plt.colorbar(im3, ax=axes[2])

        plt.suptitle(title)
        plt.tight_layout()
        plt.show()

    def predict_with_explanation(self, input_tensor: torch.Tensor, method: str = "saliency",
                                 threshold: float = 0.1, alpha: float = 0.7):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞ —Ä–∞–∑.

        Returns:
            dict: {'prediction': ..., 'explanation': ...}
        """
        prediction = self.predict(input_tensor)
        explanation = self.explain_prediction(
            input_tensor,
            target_class=prediction['prediction'],
            method=method,
            threshold=threshold,
            alpha=alpha
        )
        return {
            'prediction': prediction,
            'explanation': explanation
        }

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    def predict_batch(self, batch_tensor: torch.Tensor) -> List[Dict[str, Union[float, int, np.ndarray]]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –±–∞—Ç—á–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤."""
        with torch.no_grad():
            batch_size = batch_tensor.shape[0]
            batch_tensor = self._validate_input_tensor(batch_tensor)

            if self._half_precision:
                with torch.cuda.amp.autocast():
                    logits = self.model(batch_tensor)
            else:
                logits = self.model(batch_tensor)

            probabilities = F.softmax(logits, dim=1)
            predicted_classes = torch.argmax(probabilities, dim=1)
            confidences = torch.max(probabilities, dim=1)[0]

            logits_np = logits.cpu().numpy()
            probabilities_np = probabilities.cpu().numpy()

            results = []
            for i in range(batch_size):
                results.append({
                    'prediction': int(predicted_classes[i].item()),
                    'probabilities': probabilities_np[i],
                    'confidence': float(confidences[i].item()),
                    'logits': logits_np[i]
                })

            return results

    def predict_probability(self, input_tensor: torch.Tensor) -> np.ndarray:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤."""
        result = self.predict(input_tensor)
        return result['probabilities']

    def predict_class(self, input_tensor: torch.Tensor) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å."""
        result = self.predict(input_tensor)
        return result['prediction']


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    from config import ModelConfig

    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    config = ModelConfig()
    config.input_D = 256
    config.input_H = 256
    config.input_W = 256
    config.n_seg_classes = 2  # –ø—Ä–∏–º–µ—Ä –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

    # –°–æ–∑–¥–∞–µ–º inference –º–æ–¥—É–ª—å
    inference = MedicalModelInference(
        weights_path="model\\outputs\\weights\\best-epoch=42-val_f1=0.7650-val_auroc=0.8675.ckpt",
        model_config=config
    )

    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä 256x256x256
    test_tensor = torch.randn(1, 1, 256, 256, 256)

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    result = inference.predict(test_tensor)

    print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {result['prediction']}")
    print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.4f}")

    # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    try:
        explanation = inference.explain_prediction(
            test_tensor,
            method="saliency",
            visualize=True,
            threshold=0.2,  # –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ—Ä–æ–≥ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            alpha=0.6  # –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å
        )

        # –ò–ª–∏ –∑–∞ —Ä–∞–∑:
        full_result = inference.predict_with_explanation(
            test_tensor,
            method="saliency",
            threshold=0.2,
            alpha=0.6
        )
        print(f"–ü–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {full_result['prediction']['prediction']}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–∏: {e}")
        print("üîÑ –ü—Ä–æ–±—É–µ–º —Å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º...")

        # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º
        explanation = inference.explain_prediction(
            test_tensor,
            method="saliency",
            visualize=True,
            threshold=0.3,  # –ë–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥
            alpha=0.5
        )