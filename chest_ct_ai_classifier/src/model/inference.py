# inference.py
import torch
import torch.nn.functional as F
import numpy as np
from typing import Union, List, Dict, Optional
from pathlib import Path
from omegaconf import OmegaConf
from .model_generator import generate_model
from .lightning_module import MedicalClassificationModel
import warnings

warnings.filterwarnings("ignore", category=UserWarning)


class MedicalModelInference:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.

    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç 3D —Ç–µ–Ω–∑–æ—Ä —Ä–∞–∑–º–µ—Ä–æ–º 256x256x256 –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ.
    """

    def __init__(self,
                 weights_path: str,
                 model_config,
                 device: Optional[str] = None,
                 use_half_precision: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è inference –º–æ–¥—É–ª—è.

        Args:
            weights_path: –ø—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É –º–æ–¥–µ–ª–∏
            model_config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (ModelConfig)
            device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ('cuda' –∏–ª–∏ 'cpu'), –µ—Å–ª–∏ None - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            use_half_precision: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ half precision (float16) –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        """
        self.weights_path = Path(weights_path)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ ModelConfig
        self.model_config = model_config
        self.use_half_precision = use_half_precision

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device

        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.model = self._load_model()
        self.model.eval()

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ half precision –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.use_half_precision and self.device == 'cuda':
            self.model.half()
            self._half_precision = True
        else:
            self._half_precision = False

        print(f"‚úÖ Inference –º–æ–¥—É–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")
        print(
            f"üìä –û–∂–∏–¥–∞–µ–º—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: 1, 1, {self.model_config.input_D}, {self.model_config.input_H}, {self.model_config.input_W}")
        print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {self.model_config.n_seg_classes}")

    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏."""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ModelConfig –≤ OmegaConf
        config_dict = {
            'model': self.model_config.model,
            'model_depth': self.model_config.model_depth,
            'resnet_shortcut': self.model_config.resnet_shortcut,
            'input_W': self.model_config.input_W,
            'input_H': self.model_config.input_H,
            'input_D': self.model_config.input_D,
            'n_seg_classes': self.model_config.n_seg_classes,
            'pretrain_path': self.model_config.pretrain_path if self.model_config.use_pretrained else None,
            'no_cuda': (self.device == 'cpu'),
            'gpu_id': [0] if torch.cuda.is_available() else [],
            'phase': 'test'
        }

        omega_config = OmegaConf.create(config_dict)

        from argparse import Namespace
        args = Namespace(**config_dict)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        model, _ = generate_model(args)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        if self.device == 'cpu':
            checkpoint = torch.load(self.weights_path, map_location='cpu', weights_only=True)
        else:
            checkpoint = torch.load(self.weights_path, map_location=self.device, weights_only=True)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —á–µ–∫–ø–æ–∏–Ω—Ç Lightning –º–æ–¥—É–ª–µ–º –∏–ª–∏ –æ–±—ã—á–Ω–æ–π –º–æ–¥–µ–ª—å—é
        if 'state_dict' in checkpoint:
            # –≠—Ç–æ Lightning —á–µ–∫–ø–æ–∏–Ω—Ç
            lightning_model = MedicalClassificationModel.load_from_checkpoint(
                self.weights_path,
                model=model,
                learning_rate=self.model_config.learning_rate,
                num_classes=self.model_config.n_seg_classes
            )
            model = lightning_model.model
        else:
            # –≠—Ç–æ –æ–±—ã—á–Ω—ã–π state_dict
            model.load_state_dict(checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint)

        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        model = model.to(self.device)

        return model

    def _validate_input_tensor(self, tensor: torch.Tensor) -> torch.Tensor:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞.

        Args:
            tensor: –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä

        Returns:
            torch.Tensor: –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä
        """
        if not isinstance(tensor, torch.Tensor):
            raise TypeError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è torch.Tensor, –ø–æ–ª—É—á–µ–Ω–æ {type(tensor)}")

        if tensor.dim() != 5:
            raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è 5D —Ç–µ–Ω–∑–æ—Ä (B, C, D, H, W), –ø–æ–ª—É—á–µ–Ω–æ {tensor.shape}")

        batch_size, channels, depth, height, width = tensor.shape

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã
        expected_shape = (1, 1, self.model_config.input_D, self.model_config.input_H, self.model_config.input_W)
        if (channels, depth, height, width) != expected_shape[1:]:
            raise ValueError(
                f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã {expected_shape}, "
                f"–ø–æ–ª—É—á–µ–Ω–æ {tensor.shape}. "
                f"–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–∞–∑–º–µ—Ä—ã: channels=1, depth={self.model_config.input_D}, "
                f"height={self.model_config.input_H}, width={self.model_config.input_W}"
            )

        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏ —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
        tensor = tensor.to(self.device)

        if self._half_precision:
            tensor = tensor.half()
        else:
            tensor = tensor.float()

        return tensor

    def predict(self, input_tensor: torch.Tensor) -> Dict[str, Union[float, int, np.ndarray]]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º —Ç–µ–Ω–∑–æ—Ä–µ.

        Args:
            input_tensor: —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã (1, 1, input_D, input_H, input_W)

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:
            - prediction: –∫–ª–∞—Å—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (int)
            - probabilities: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤ (numpy array)
            - confidence: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ (float)
            - logits: –ª–æ–≥–∏—Ç—ã (numpy array)
        """
        with torch.no_grad():
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–∞
            input_tensor = self._validate_input_tensor(input_tensor)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            if self._half_precision:
                with torch.cuda.amp.autocast():
                    logits = self.model(input_tensor)
            else:
                logits = self.model(input_tensor)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º softmax –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            probabilities = F.softmax(logits, dim=1)

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å
            predicted_class = torch.argmax(probabilities, dim=1).item()
            confidence = torch.max(probabilities, dim=1)[0].item()

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
            logits_np = logits.cpu().numpy()
            probabilities_np = probabilities.cpu().numpy()

            return {
                'prediction': int(predicted_class),
                'probabilities': probabilities_np.squeeze(),
                'confidence': float(confidence),
                'logits': logits_np.squeeze()
            }

    def predict_batch(self, batch_tensor: torch.Tensor) -> List[Dict[str, Union[float, int, np.ndarray]]]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –±–∞—Ç—á–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤.

        Args:
            batch_tensor: —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã (B, 1, input_D, input_H, input_W)

        Returns:
            List[Dict] - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ –±–∞—Ç—á–µ
        """
        with torch.no_grad():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            batch_size = batch_tensor.shape[0]

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–∞
            batch_tensor = self._validate_input_tensor(batch_tensor)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            if self._half_precision:
                with torch.cuda.amp.autocast():
                    logits = self.model(batch_tensor)
            else:
                logits = self.model(batch_tensor)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º softmax
            probabilities = F.softmax(logits, dim=1)

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ–≥–æ –±–∞—Ç—á–∞
            predicted_classes = torch.argmax(probabilities, dim=1)
            confidences = torch.max(probabilities, dim=1)[0]

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
            logits_np = logits.cpu().numpy()
            probabilities_np = probabilities.cpu().numpy()

            results = []
            for i in range(batch_size):
                results.append({
                    'prediction': int(predicted_classes[i].item()),
                    'probabilities': probabilities_np[i],
                    'confidence': float(confidences[i].item()),
                    'logits': logits_np[i]
                })

            return results

    def predict_probability(self, input_tensor: torch.Tensor) -> np.ndarray:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤.

        Args:
            input_tensor: —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã (1, 1, input_D, input_H, input_W)

        Returns:
            np.ndarray: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
        """
        result = self.predict(input_tensor)
        return result['probabilities']

    def predict_class(self, input_tensor: torch.Tensor) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å.

        Args:
            input_tensor: —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã (1, 1, input_D, input_H, input_W)

        Returns:
            int: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å
        """
        result = self.predict(input_tensor)
        return result['prediction']


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    from config import ModelConfig

    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    config = ModelConfig()
    config.input_D = 256
    config.input_H = 256
    config.input_W = 256
    config.n_seg_classes = 2  # –ø—Ä–∏–º–µ—Ä –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

    # –°–æ–∑–¥–∞–µ–º inference –º–æ–¥—É–ª—å
    inference = MedicalModelInference(
        weights_path="/model/outputs/weights/best-epoch=00-val_f1=0.6222-val_auroc=0.6858.ckpt",

        model_config=config
    )

    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä 256x256x256
    test_tensor = torch.randn(1, 1, 256, 256, 256)

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    result = inference.predict(test_tensor)

    print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {result['prediction']}")
    print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.4f}")
    print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤: {result['probabilities']}")

    # –ü—Ä–∏–º–µ—Ä –±–∞—Ç—á–µ–≤–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    batch_tensor = torch.randn(3, 1, 256, 256, 256)
    batch_results = inference.predict_batch(batch_tensor)

    for i, res in enumerate(batch_results):
        print(f"–û–±—Ä–∞–∑–µ—Ü {i}: –∫–ª–∞—Å—Å={res['prediction']}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={res['confidence']:.4f}")