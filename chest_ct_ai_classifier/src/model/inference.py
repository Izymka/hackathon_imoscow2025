import torch
import torch.nn.functional as F
import numpy as np
from typing import Union, Dict, List, Optional
from pathlib import Path
import argparse

# –ò–∑–º–µ–Ω—è–µ–º –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã –∫–∞–∫ –º–æ–¥—É–ª—è, —Ç–∞–∫ –∏ –∫–∞–∫ standalone —Å–∫—Ä–∏–ø—Ç–∞
try:
    from .config import ModelConfig
    # from .model_generator import generate_model  # –£–±—Ä–∞–ª–∏ –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç
except ImportError:
    from config import ModelConfig
    # from model_generator import generate_model  # –£–±—Ä–∞–ª–∏ –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç

import warnings
warnings.filterwarnings('ignore')

import torch
from torch import nn

# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã –∫–∞–∫ –º–æ–¥—É–ª—è, —Ç–∞–∫ –∏ –∫–∞–∫ standalone —Å–∫—Ä–∏–ø—Ç–∞
try:
    from .models import resnet
except ImportError:
    try:
        from models import resnet
    except ImportError:
        import models.resnet as resnet

def generate_model(opt):
    assert opt.model in [
        'resnet'
    ]

    if opt.model == 'resnet':
        assert opt.model_depth in [10, 18, 34, 50, 101, 152, 200]
        
        if opt.model_depth == 10:
            model = resnet.resnet10(
                sample_input_W=opt.input_W,
                sample_input_H=opt.input_H,
                sample_input_D=opt.input_D,
                shortcut_type=opt.resnet_shortcut,
                no_cuda=opt.no_cuda,
                num_seg_classes=opt.n_seg_classes)
        elif opt.model_depth == 18:
            model = resnet.resnet18(
                sample_input_W=opt.input_W,
                sample_input_H=opt.input_H,
                sample_input_D=opt.input_D,
                shortcut_type=opt.resnet_shortcut,
                no_cuda=opt.no_cuda,
                num_seg_classes=opt.n_seg_classes)
        elif opt.model_depth == 34:
            model = resnet.resnet34(
                sample_input_W=opt.input_W,
                sample_input_H=opt.input_H,
                sample_input_D=opt.input_D,
                shortcut_type=opt.resnet_shortcut,
                no_cuda=opt.no_cuda,
                num_seg_classes=opt.n_seg_classes)
        elif opt.model_depth == 50:
            model = resnet.resnet50(
                sample_input_W=opt.input_W,
                sample_input_H=opt.input_H,
                sample_input_D=opt.input_D,
                shortcut_type=opt.resnet_shortcut,
                no_cuda=opt.no_cuda,
                num_seg_classes=opt.n_seg_classes)
        elif opt.model_depth == 101:
            model = resnet.resnet101(
                sample_input_W=opt.input_W,
                sample_input_H=opt.input_H,
                sample_input_D=opt.input_D,
                shortcut_type=opt.resnet_shortcut,
                no_cuda=opt.no_cuda,
                num_seg_classes=opt.n_seg_classes)
        elif opt.model_depth == 152:
            model = resnet.resnet152(
                sample_input_W=opt.input_W,
                sample_input_H=opt.input_H,
                sample_input_D=opt.input_D,
                shortcut_type=opt.resnet_shortcut,
                no_cuda=opt.no_cuda,
                num_seg_classes=opt.n_seg_classes)
        elif opt.model_depth == 200:
            model = resnet.resnet200(
                sample_input_W=opt.input_W,
                sample_input_H=opt.input_H,
                sample_input_D=opt.input_D,
                shortcut_type=opt.resnet_shortcut,
                no_cuda=opt.no_cuda,
                num_seg_classes=opt.n_seg_classes)
    
    if not opt.no_cuda:
        if len(opt.gpu_id) > 1:
            model = model.cuda() 
            model = nn.DataParallel(model, device_ids=opt.gpu_id)
            net_dict = model.state_dict() 
        else:
            import os
            os.environ["CUDA_VISIBLE_DEVICES"]=str(opt.gpu_id[0])
            model = model.cuda() 
            model = nn.DataParallel(model, device_ids=None)
            net_dict = model.state_dict()
    else:
        net_dict = model.state_dict()
    
    # load pretrain
    if opt.phase != 'test' and opt.pretrain_path:
        print('loading pretrained model {}'.format(opt.pretrain_path))
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è CPU/GPU —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        if opt.no_cuda or not torch.cuda.is_available():
            pretrain = torch.load(opt.pretrain_path, weights_only=True, map_location=torch.device('cpu'))
        else:
            pretrain = torch.load(opt.pretrain_path, weights_only=True)

        pretrain_dict = {k: v for k, v in pretrain['state_dict'].items() if k in net_dict.keys()}

        net_dict.update(pretrain_dict)
        model.load_state_dict(net_dict)

        new_parameters = []
        for pname, p in model.named_parameters():
            for layer_name in opt.new_layer_names:
                if pname.find(layer_name) >= 0:
                    new_parameters.append(p)
                    break

        new_parameters_id = list(map(id, new_parameters))
        base_parameters = list(filter(lambda p: id(p) not in new_parameters_id, model.parameters()))
        parameters = {'base_parameters': base_parameters,
                      'new_parameters': new_parameters}

        return model, parameters

    return model, model.parameters()


class MedicalModelInference:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –ó–∞–≥—Ä—É–∑–∫—É –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    - –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
    - –ü–∞–∫–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    - –í–æ–∑–≤—Ä–∞—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ –∫–ª–∞—Å—Å–æ–≤
    - GPU/CPU —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
    """
    
    def __init__(self, 
                 weights_path: str, 
                 model_config: Optional[ModelConfig] = None,
                 device: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è inference –∫–ª–∞—Å—Å–∞.
        
        Args:
            weights_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ (.pth)
            model_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π ('cuda', 'cpu', –∏–ª–∏ None –¥–ª—è –∞–≤—Ç–æ–≤—ã–±–æ—Ä–∞)
        """
        self.weights_path = Path(weights_path)
        self.config = model_config or ModelConfig()
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        print(f"üñ•Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        self.model = self._load_model()
        self.model.eval()
        
        # –ù–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
        self.class_names = ['–ó–¥–æ—Ä–æ–≤', '–ë–æ–ª–µ–Ω']  # –ò–∑–º–µ–Ω–∏—Ç–µ –ø–æ–¥ —Å–≤–æ–∏ –∫–ª–∞—Å—Å—ã
        
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π!")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
        self._test_model()
    
    def _test_model(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç."""
        try:
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä
            test_input = torch.randn(1, 1, self.config.input_D, 
                                   self.config.input_H, self.config.input_W).to(self.device)
            
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏
            with torch.no_grad():
                test_output = self.model(test_input)
                
            print(f"üß™ –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ. –§–æ—Ä–º–∞ –≤—ã–≤–æ–¥–∞: {test_output.shape}")
            print(f"üß™ –ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞: {test_output[0].cpu().numpy()}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –≤–µ—Å–∞–º–∏."""
        if not self.weights_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –≤–µ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.weights_path}")
        
        print(f"üìù –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏:")
        print(f"   - –¢–∏–ø –º–æ–¥–µ–ª–∏: {self.config.model}")
        print(f"   - –ì–ª—É–±–∏–Ω–∞: {self.config.model_depth}")
        print(f"   - –ö–ª–∞—Å—Å—ã: {self.config.n_seg_classes}")
        print(f"   - –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞: {self.config.input_D}x{self.config.input_H}x{self.config.input_W}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
        cfg_dict = {
            'model': self.config.model,
            'model_depth': self.config.model_depth,
            'n_seg_classes': self.config.n_seg_classes,
            'no_cuda': self.device.type == 'cpu',
            'input_W': self.config.input_W,
            'input_H': self.config.input_H,
            'input_D': self.config.input_D,
            'resnet_shortcut': self.config.resnet_shortcut,
            'gpu_id': [] if self.device.type == 'cpu' else [0],
            'phase': 'test',
            'pin_memory': False,
            'pretrain_path': '',
            'new_layer_names': self.config.new_layer_names
        }
        
        cfg_namespace = argparse.Namespace(**cfg_dict)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        print("üèóÔ∏è –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏...")
        model, _ = generate_model(cfg_namespace)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ –∏–∑: {self.weights_path}")
        try:
            checkpoint = torch.load(self.weights_path, map_location=self.device, weights_only=True)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤: {e}")
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–µ–∑ weights_only –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π PyTorch
            try:
                checkpoint = torch.load(self.weights_path, map_location=self.device)
            except Exception as e2:
                print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤: {e2}")
                raise
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤–µ—Å–æ–≤
        if isinstance(checkpoint, dict):
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            elif 'model' in checkpoint:
                state_dict = checkpoint['model']
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(state_dict)} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ checkpoint")
        
        # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –≤ –∫–ª—é—á–∞—Ö (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ —Å DataParallel)
        from collections import OrderedDict
        new_state_dict = OrderedDict()
        for k, v in state_dict.items():
            if k.startswith('module.'):
                name = k[7:]  # —É–±–∏—Ä–∞–µ–º 'module.'
            elif k.startswith('model.'):
                name = k[6:]  # —É–±–∏—Ä–∞–µ–º 'model.'
            else:
                name = k
            new_state_dict[name] = v
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–ª—é—á–µ–π –º–æ–¥–µ–ª–∏ –∏ checkpoint
        model_keys = set(model.state_dict().keys())
        checkpoint_keys = set(new_state_dict.keys())
        
        missing_keys = model_keys - checkpoint_keys
        unexpected_keys = checkpoint_keys - model_keys
        
        if missing_keys:
            print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–ª—é—á–∏ –≤ checkpoint: {missing_keys}")
        if unexpected_keys:
            print(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏ –≤ checkpoint: {unexpected_keys}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        try:
            model.load_state_dict(new_state_dict, strict=False)
            print("‚úÖ –í–µ—Å–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤ –≤ –º–æ–¥–µ–ª—å: {e}")
            raise
        
        model = model.to(self.device)
        
        return model
    
    def _validate_input(self, tensor: torch.Tensor) -> torch.Tensor:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞."""
        if not isinstance(tensor, torch.Tensor):
            raise TypeError("–í—Ö–æ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å torch.Tensor")
        
        expected_shape = (self.config.input_D, self.config.input_H, self.config.input_W)
        
        # –ï—Å–ª–∏ —Ç–µ–Ω–∑–æ—Ä –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É [1, 1, D, H, W] - —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
        if len(tensor.shape) == 5 and tensor.shape[0] == 1 and tensor.shape[1] == 1:
            actual_shape = tensor.shape[2:]
            if actual_shape != expected_shape:
                raise ValueError(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ç–µ–Ω–∑–æ—Ä–∞: {actual_shape}, –æ–∂–∏–¥–∞–ª—Å—è: {expected_shape}")
        
        # –ï—Å–ª–∏ —Ç–µ–Ω–∑–æ—Ä –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É [1, D, H, W] - –¥–æ–±–∞–≤–ª—è–µ–º channel dimension
        elif len(tensor.shape) == 4 and tensor.shape[0] == 1:
            actual_shape = tensor.shape[1:]
            if actual_shape != expected_shape:
                raise ValueError(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ç–µ–Ω–∑–æ—Ä–∞: {actual_shape}, –æ–∂–∏–¥–∞–ª—Å—è: {expected_shape}")
            tensor = tensor.unsqueeze(1)  # [1, 1, D, H, W]
        
        # –ï—Å–ª–∏ —Ç–µ–Ω–∑–æ—Ä –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É [D, H, W] - –¥–æ–±–∞–≤–ª—è–µ–º batch –∏ channel dimensions
        elif len(tensor.shape) == 3:
            if tensor.shape != expected_shape:
                raise ValueError(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ç–µ–Ω–∑–æ—Ä–∞: {tensor.shape}, –æ–∂–∏–¥–∞–ª—Å—è: {expected_shape}")
            tensor = tensor.unsqueeze(0).unsqueeze(0)  # [1, 1, D, H, W]
        
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Ñ–æ—Ä–º–∞ —Ç–µ–Ω–∑–æ—Ä–∞: {tensor.shape}")
        
        return tensor.to(self.device)
    
    @torch.no_grad()
    def predict(self, input_tensor: torch.Tensor) -> Dict[str, Union[int, float, List[float]]]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞.
        
        Args:
            input_tensor: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä [1, 1, 128, 128, 128] –∏–ª–∏ [128, 128, 128]
            
        Returns:
            dict: {
                'predicted_class': int,
                'predicted_class_name': str,
                'confidence': float,
                'probabilities': List[float]
            }
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–∞
        tensor = self._validate_input(input_tensor)
        
        print(f"üîç –í—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä –ø–æ—Å–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {tensor.shape}")
        print(f"üîç –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞: min={tensor.min():.4f}, max={tensor.max():.4f}, mean={tensor.mean():.4f}")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        outputs = self.model(tensor)
        print(f"üîç –°—ã—Ä–æ–π –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏: {outputs}")
        print(f"üîç –§–æ—Ä–º–∞ –≤—ã–≤–æ–¥–∞: {outputs.shape}")
        
        probabilities = F.softmax(outputs, dim=1)
        print(f"üîç –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ softmax: {probabilities}")
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        predicted_class = torch.argmax(probabilities, dim=1).item()
        confidence = probabilities[0, predicted_class].item()
        probs_list = probabilities[0].cpu().numpy().tolist()
        
        result = {
            'predicted_class': predicted_class,
            'predicted_class_name': self.class_names[predicted_class],
            'confidence': confidence,
            'probabilities': probs_list
        }
        
        return result

def debug_inference():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ inference."""
    print("üîß –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ inference...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å –∫ –≤–µ—Å–∞–º
    weights_path = "model/outputs/weights/best_weights.pth"
    if not Path(weights_path).exists():
        print(f"‚ùå –§–∞–π–ª –≤–µ—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {weights_path}")
        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø—É—Ç–∏
        possible_paths = [
            "model/outputs/checkpoints/best_weights.pth",
            "outputs/weights/best_weights.pth",
            "outputs/checkpoints/best_weights.pth"
        ]
        for path in possible_paths:
            if Path(path).exists():
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å: {path}")
                weights_path = path
                break
        else:
            print("‚ùå –í–µ—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ –ø–æ –æ–¥–Ω–æ–º—É –∏–∑ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—É—Ç–µ–π")
            return
    
    # –°–æ–∑–¥–∞–µ–º inference
    try:
        inference = MedicalModelInference(weights_path)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä
        pneumotorax = torch.randn(128, 128, 128)  # –í–∞—à —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        result = inference.predict(pneumotorax)
        
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {result}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ debug_inference: {e}")
        import traceback
        traceback.print_exc()


def read_tensor(path: Path) -> torch.Tensor:
    """–ß—Ç–µ–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–∞ –∏–∑ PyTorch —Ñ–∞–π–ª–∞ (.pt, .pth)"""
    try:
        tensor = torch.load(path, weights_only=False, map_location='cpu')

        # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å —Å 'state_dict' –∏–ª–∏ 'tensor', –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–Ω–∑–æ—Ä
        if isinstance(tensor, dict):
            if 'tensor' in tensor:
                tensor = tensor['tensor']
            elif 'state_dict' in tensor:
                # –≠—Ç–æ —á–µ–∫–ø–æ–∏–Ω—Ç –º–æ–¥–µ–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å –∏–ª–∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–Ω–∑–æ—Ä
                raise ValueError(
                    "–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç state_dict –º–æ–¥–µ–ª–∏, –∞ –Ω–µ —Ç–µ–Ω–∑–æ—Ä. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ load_state_dict –¥–ª—è –º–æ–¥–µ–ª–∏.")
            else:
                # –ï—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—å —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–Ω–∑–æ—Ä, –∏–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤—ã–π
                for key, value in tensor.items():
                    if isinstance(value, torch.Tensor):
                        return value
                raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω —Ç–µ–Ω–∑–æ—Ä –≤ —Å–ª–æ–≤–∞—Ä–µ")

        if not isinstance(tensor, torch.Tensor):
            raise ValueError(f"–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–Ω–∑–æ—Ä, –∞ —Å–æ–¥–µ—Ä–∂–∏—Ç: {type(tensor)}")

        return tensor

    except Exception as e:
        raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PyTorch —Ñ–∞–π–ª–∞: {e}")

if __name__ == "__main__":
    #debug_inference()
    test_path = Path("../data/test_ideal/norma_anon.pt")
    if not test_path.exists():
        raise FileNotFoundError(f"Test file not found at path: {test_path}")
    pneumonia = read_tensor(test_path)
    inference = MedicalModelInference("outputs/weights/best_weights.pth")
    predict_result = inference.predict(pneumonia)
    print(predict_result)