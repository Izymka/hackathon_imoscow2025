import time

import torch
import torch.nn.functional as F
import numpy as np
from typing import Union, List, Dict, Optional
from pathlib import Path
from omegaconf import OmegaConf
import warnings
import os
import gc

os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# –ó–∞–º–µ–Ω—è–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from .model_generator import generate_model
from .lightning_module import MedicalClassificationModel


# –î–æ–±–∞–≤–ª—è–µ–º Captum
try:
    from captum.attr import IntegratedGradients, Saliency, LayerGradCam, LayerAttribution
    from captum.attr import visualization as viz
    import matplotlib.pyplot as plt
    from matplotlib.colors import LinearSegmentedColormap

    CAPTUM_AVAILABLE = True
except ImportError:
    CAPTUM_AVAILABLE = False
    print("‚ö†Ô∏è Captum –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install captum")

warnings.filterwarnings("ignore", category=UserWarning)


class MedicalModelInference:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.

    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç 3D —Ç–µ–Ω–∑–æ—Ä —Ä–∞–∑–º–µ—Ä–æ–º 256x256x256 –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ.
    """

    def __init__(self,
                 weights_path: str,
                 model_config: 'ModelConfig',  # –ò–∑–º–µ–Ω–∏–ª–∏ —Ç–∏–ø –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
                 device: Optional[str] = None,
                 use_half_precision: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è inference –º–æ–¥—É–ª—è.

        Args:
            weights_path: –ø—É—Ç—å –∫ —á–µ–∫–ø–æ–∏–Ω—Ç—É –º–æ–¥–µ–ª–∏
            model_config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (ModelConfig)
            device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ('cuda' –∏–ª–∏ 'cpu'), –µ—Å–ª–∏ None - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            use_half_precision: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ half precision (float16) –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        """
        self.weights_path = Path(weights_path)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º ModelConfig –≤ OmegaConf
        if isinstance(model_config, dict):
            self.model_config = OmegaConf.create(model_config)
        elif hasattr(model_config, '__dict__'):  # –≠—Ç–æ ModelConfig (dataclass)
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º dataclass –≤ —Å–ª–æ–≤–∞—Ä—å, –∑–∞—Ç–µ–º –≤ OmegaConf
            config_dict = {}
            for field_name in dir(model_config):
                if not field_name.startswith('_'):
                    try:
                        value = getattr(model_config, field_name)
                        if not callable(value):
                            config_dict[field_name] = value
                    except:
                        continue
            self.model_config = OmegaConf.create(config_dict)
        else:
            self.model_config = model_config if isinstance(model_config, OmegaConf) else OmegaConf.create(model_config)

        self.use_half_precision = use_half_precision

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device

        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.model = self._load_model()
        self.model.eval()

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ half precision –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if self.use_half_precision and self.device == 'cuda':
            self.model.half()
            self._half_precision = True
        else:
            self._half_precision = False

        print(f"‚úÖ Inference –º–æ–¥—É–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")
        print(f"üìä –û–∂–∏–¥–∞–µ–º—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: 1, 1, 256, 256, 256")
        print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {self.model_config.n_seg_classes}")

    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å —É—Å—Ç–æ–π—á–∏–≤–æ–π –ø–æ–¥–≥–æ–Ω–∫–æ–π –∫–ª—é—á–µ–π state_dict."""
        from argparse import Namespace
        from collections import OrderedDict

        print("=" * 60)
        print("üîß –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ namespace
        config_dict = OmegaConf.to_container(self.model_config)
        config_dict['gpu_id'] = [0] if torch.cuda.is_available() else []
        config_dict['phase'] = 'test'  # –í–ê–ñ–ù–û: —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∞
        config_dict['no_cuda'] = (self.device == 'cpu')

        args = Namespace(**config_dict)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—Å—Ç—É—é –º–æ–¥–µ–ª—å —Ü–µ–ª–µ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        model, _ = generate_model(args)
        print("=" * 60)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç (CPU-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ)
        try:
            checkpoint = torch.load(
                self.weights_path,
                map_location=('cpu' if self.device == 'cpu' else self.device),
                weights_only=False
            )
            print(f"üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω checkpoint. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª—é—á–∏: {list(checkpoint.keys())}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ checkpoint: {e}")
            raise

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ state_dict –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
        state_dict = None

        # –ü–æ–ø—ã—Ç–∫–∞ 1: PyTorch Lightning (.ckpt)
        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
            print("üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω —Ñ–æ—Ä–º–∞—Ç PyTorch Lightning (.ckpt)")

        # –ü–æ–ø—ã—Ç–∫–∞ 2: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π PyTorch —Å –æ–±—ë—Ä—Ç–∫–æ–π
        elif isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
            print("üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω —Ñ–æ—Ä–º–∞—Ç model_state_dict (.pth)")

        # –ü–æ–ø—ã—Ç–∫–∞ 3: –ü—Ä—è–º–æ–π state_dict (.pth) - —á–∏—Å—Ç—ã–µ –≤–µ—Å–∞
        elif isinstance(checkpoint, dict):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ–Ω–∑–æ—Ä—ã –Ω–∞–ø—Ä—è–º—É—é –≤ checkpoint
            tensor_keys = [k for k, v in checkpoint.items() if isinstance(v, torch.Tensor)]

            if len(tensor_keys) > 0:
                # –≠—Ç–æ –ø—Ä—è–º–æ–π state_dict
                state_dict = checkpoint
                print("üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø—Ä—è–º–æ–π state_dict (.pth)")
            else:
                # –í–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                # –ò—â–µ–º –ª—é–±–æ–π –∫–ª—é—á, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤–µ—Å–∞
                possible_keys = ['model', 'net', 'network', 'weights', 'parameters']
                for key in possible_keys:
                    if key in checkpoint and isinstance(checkpoint[key], dict):
                        state_dict = checkpoint[key]
                        print(f"üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω state_dict –≤ –∫–ª—é—á–µ '{key}'")
                        break

        # –ü–æ–ø—ã—Ç–∫–∞ 4: –ï—Å–ª–∏ —ç—Ç–æ –≤–æ–æ–±—â–µ –Ω–µ —Å–ª–æ–≤–∞—Ä—å (—Ä–µ–¥–∫–∏–π —Å–ª—É—á–∞–π)
        else:
            print("‚ö†Ô∏è Checkpoint –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º, –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞–ø—Ä—è–º—É—é")
            state_dict = checkpoint

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if state_dict is None or (isinstance(state_dict, dict) and len(state_dict) == 0):
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ state_dict –≤ checkpoint")
            print(
                f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª—é—á–∏ –≤ checkpoint: {list(checkpoint.keys()) if isinstance(checkpoint, dict) else 'N/A'}")
            raise ValueError("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç checkpoint. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏.")

        # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–∏ —Ü–µ–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        target_keys = set(model.state_dict().keys())
        sample_target_key = list(target_keys)[0] if target_keys else ""
        sample_source_key = list(state_dict.keys())[0] if state_dict else ""

        print(f"üîç –ü—Ä–∏–º–µ—Ä –∫–ª—é—á–∞ –≤ –º–æ–¥–µ–ª–∏: {sample_target_key}")
        print(f"üîç –ü—Ä–∏–º–µ—Ä –∫–ª—é—á–∞ –≤ checkpoint: {sample_source_key}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –¥–æ–±–∞–≤–ª—è—Ç—å –∏–ª–∏ —É–¥–∞–ª—è—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å
        needs_module_prefix = any(k.startswith('module.') for k in target_keys)
        has_module_prefix = any(k.startswith('module.') for k in state_dict.keys())

        print(f"üîß –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç 'module.' –ø—Ä–µ—Ñ–∏–∫—Å: {needs_module_prefix}")
        print(f"üîß Checkpoint –∏–º–µ–µ—Ç 'module.' –ø—Ä–µ—Ñ–∏–∫—Å: {has_module_prefix}")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
        new_state_dict = OrderedDict()
        skipped_keys = []

        for k, v in state_dict.items():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
            skip_patterns = [
                'loss_fn', 'criterion', 'optimizer', 'scheduler',
                'class_weights', 'loss_weights', 'weight_decay',
                'learning_rate', 'momentum', 'best_score'
            ]

            if any(pattern in k for pattern in skip_patterns):
                skipped_keys.append(k)
                continue

            new_key = k

            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
            for prefix in ['model.module.', 'model.', 'net.', 'encoder.']:
                if new_key.startswith(prefix):
                    new_key = new_key[len(prefix):]
                    break

            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è 'module.'
            if new_key.startswith('module.'):
                new_key = new_key[7:]  # —É–±–∏—Ä–∞–µ–º 'module.'

            # –î–æ–±–∞–≤–ª—è–µ–º 'module.' –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç, –∞ –µ–≥–æ –Ω–µ—Ç
            if needs_module_prefix and not new_key.startswith('module.'):
                new_key = 'module.' + new_key
            # –£–±–∏—Ä–∞–µ–º 'module.' –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —Ç—Ä–µ–±—É–µ—Ç, –∞ –æ–Ω –µ—Å—Ç—å
            elif not needs_module_prefix and new_key.startswith('module.'):
                new_key = new_key[7:]

            new_state_dict[new_key] = v

        print(f"üîë –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–ª—é—á–µ–π: {len(new_state_dict)}")
        if skipped_keys:
            print(
                f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ —Å–ª—É–∂–µ–±–Ω—ã—Ö –∫–ª—é—á–µ–π: {len(skipped_keys)} ({', '.join(skipped_keys[:3])}{'...' if len(skipped_keys) > 3 else ''})")
        if new_state_dict:
            print(f"üîç –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–ª—é—á–∞: {list(new_state_dict.keys())[0]}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ state_dict –≤ –º–æ–¥–µ–ª—å —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            missing_keys, unexpected_keys = model.load_state_dict(new_state_dict, strict=False)

            # –°—á–∏—Ç–∞–µ–º —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∫–ª—é—á–∏
            loaded_keys = len(new_state_dict) - len(unexpected_keys)
            total_model_keys = len(model.state_dict())

            if missing_keys:
                print(
                    f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–ª—é—á–∏ ({len(missing_keys)}): {missing_keys[:3]}{'...' if len(missing_keys) > 3 else ''}")
            if unexpected_keys:
                print(
                    f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏ ({len(unexpected_keys)}): {unexpected_keys[:3]}{'...' if len(unexpected_keys) > 3 else ''}")

            # –£—Å–ø–µ—à–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
            if not missing_keys and not unexpected_keys:
                print("‚úÖ –í—Å–µ –∫–ª—é—á–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
            elif loaded_keys >= total_model_keys * 0.95:  # –ó–∞–≥—Ä—É–∂–µ–Ω–æ >= 95%
                print(
                    f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_keys}/{total_model_keys} –∫–ª—é—á–µ–π ({loaded_keys / total_model_keys * 100:.1f}%) - –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã!")
            else:
                print(
                    f"üîÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_keys}/{total_model_keys} –∫–ª—é—á–µ–π ({loaded_keys / total_model_keys * 100:.1f}%)")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ strict –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
            print("üîÑ –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∫–ª—é—á–∏...")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∫–ª—é—á–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É
            model_dict = model.state_dict()
            filtered_dict = {
                k: v for k, v in new_state_dict.items()
                if k in model_dict and v.shape == model_dict[k].shape
            }

            model_dict.update(filtered_dict)
            model.load_state_dict(model_dict)
            print(
                f"üîÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(filtered_dict)} –∏–∑ {len(new_state_dict)} –∫–ª—é—á–µ–π ({len(filtered_dict) / len(model_dict) * 100:.1f}%)")

        # –£–±–∏—Ä–∞–µ–º DataParallel wrapper –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if hasattr(model, 'module'):
            print("üîß –£–±–∏—Ä–∞–µ–º DataParallel wrapper...")
            model = model.module

        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        model = model.to(self.device)
        model.eval()

        print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å—É!")
        print("=" * 60)

        return model

    def _validate_input_tensor(self, tensor: torch.Tensor) -> torch.Tensor:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞."""
        if not isinstance(tensor, torch.Tensor):
            raise TypeError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è torch.Tensor, –ø–æ–ª—É—á–µ–Ω–æ {type(tensor)}")

        if tensor.dim() != 5:
            raise ValueError(f"–û–∂–∏–¥–∞–µ—Ç—Å—è 5D —Ç–µ–Ω–∑–æ—Ä (B, C, D, H, W), –ø–æ–ª—É—á–µ–Ω–æ {tensor.shape}")

        batch_size, channels, depth, height, width = tensor.shape

        expected_shape = (1, 1, 256, 256, 256)
        if (channels, depth, height, width) != expected_shape[1:]:
            raise ValueError(
                f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã {expected_shape}, "
                f"–ø–æ–ª—É—á–µ–Ω–æ {tensor.shape}. "
                f"–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–∞–∑–º–µ—Ä—ã: channels=1, depth=256, height=256, width=256"
            )

        tensor = tensor.to(self.device)

        if self._half_precision:
            tensor = tensor.half()
        else:
            tensor = tensor.float()

        return tensor

    def _free_memory(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ GPU –∏ —Å–±–æ—Ä –º—É—Å–æ—Ä–∞."""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    def predict(self, input_tensor: torch.Tensor) -> Dict[str, Union[float, int, np.ndarray]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º —Ç–µ–Ω–∑–æ—Ä–µ."""
        with torch.no_grad():
            input_tensor = self._validate_input_tensor(input_tensor)

            if self._half_precision:
                with torch.cuda.amp.autocast():
                    logits = self.model(input_tensor)
            else:
                logits = self.model(input_tensor)

            probabilities = F.softmax(logits, dim=1)
            predicted_class = torch.argmax(probabilities, dim=1).item()
            confidence = torch.max(probabilities, dim=1)[0].item()

            logits_np = logits.cpu().numpy()
            probabilities_np = probabilities.cpu().numpy()

            # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            self._free_memory()

            return {
                'prediction': int(predicted_class),
                'probabilities': probabilities_np.squeeze(),
                'confidence': float(confidence),
                'logits': logits_np.squeeze()
            }

    def explain_prediction(self, input_tensor: torch.Tensor, target_class: Optional[int] = 1,
                           method: str = "saliency", visualize: bool = True,
                           threshold: float = 0.1, alpha: float = 0.7, save_png: bool = False):
        """
        –û–±—ä—è—Å–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Captum.

        Args:
            input_tensor: —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º—ã (1, 1, 256, 256, 256)
            target_class: –∫–ª–∞—Å—Å –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π)
            method: –º–µ—Ç–æ–¥ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è ('integrated_gradients', 'saliency')
            visualize: –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
            threshold: –ø–æ—Ä–æ–≥ –¥–ª—è –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–∞–±—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ (0-1)
            alpha: –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –Ω–∞–ª–æ–∂–µ–Ω–∏—è —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã

        Returns:
            attributions: –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ (—Ç–µ–Ω–∑–æ—Ä —Å —Ç–µ–º –∂–µ —Ä–∞–∑–º–µ—Ä–æ–º, —á—Ç–æ –∏ –≤—Ö–æ–¥)
        """
        if not CAPTUM_AVAILABLE:
            raise ImportError("Captum –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install captum")

        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
            original_tensor = input_tensor.clone()
            input_tensor = self._validate_input_tensor(input_tensor)

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            if target_class is None:
                prediction_result = self.predict(original_tensor)
                target_class = prediction_result['prediction']

            print(f"üéØ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∞ {target_class} —Å –º–µ—Ç–æ–¥–æ–º {method}")

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–Ω–∑–æ—Ä –¥–ª—è –∞—Ç—Ä–∏–±—É—Ü–∏–∏
            input_tensor = input_tensor.detach()
            input_tensor.requires_grad_(False)

            # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            self._free_memory()

            # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏
            if method == "integrated_gradients":
                explainer = IntegratedGradients(self.model)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–µ —à–∞–≥–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                with torch.no_grad():
                    attributions = explainer.attribute(input_tensor, target=target_class, n_steps=2)
            elif method == "saliency":
                explainer = Saliency(self.model)
                with torch.no_grad():
                    attributions = explainer.attribute(input_tensor, target=target_class, abs=False)
            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –º–µ—Ç–æ–¥: {method}")

            if visualize:
                self._visualize_3d_attributions_enhanced(
                    attributions, original_tensor,
                    title=f"Attributions ({method})",
                    threshold=threshold,
                    alpha=alpha
                )

            if save_png:
                saved_image = self._visualize_3d_attributions_enhanced(
                    attributions, original_tensor,
                    title=f"Attributions ({method})",
                    threshold=threshold,
                    alpha=alpha,
                    return_png=True
                )
                attributions["image"] = saved_image

            return attributions

        except RuntimeError as e:
            if "out of memory" in str(e):
                print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ GPU –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
                print("   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å method='saliency'")
                print("   - –£–≤–µ–ª–∏—á–∏—Ç—å threshold (–Ω–∞–ø—Ä–∏–º–µ—Ä, 0.3)")
                print("   - –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ CPU")
                self._free_memory()
                return None
            else:
                raise e

    def _visualize_3d_attributions_enhanced(self, attributions, original_tensor,
                                            title="Attributions", threshold=0.1, alpha=0.7, return_png=False):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ–º –Ω—É–ª–µ–π –∏ –Ω–∞–ª–æ–∂–µ–Ω–∏–µ–º."""
        attr_np = attributions.squeeze().detach().cpu().numpy()
        original_np = original_tensor.squeeze().detach().cpu().numpy()

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        original_normalized = (original_np - original_np.min()) / (original_np.max() - original_np.min())

        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –∑–Ω–∞—á–∏–º—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤
        attr_abs = np.abs(attr_np)
        attr_max = np.max(attr_abs)

        if attr_max > 0:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
            attr_normalized = attr_abs / attr_max
            mask = attr_normalized > threshold
        else:
            mask = np.zeros_like(attr_abs, dtype=bool)

        mid_slice = attr_np.shape[0] // 2

        # –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—É—é colormap —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é –¥–ª—è –Ω–∏–∑–∫–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        colors = plt.cm.hot(np.linspace(0, 1, 256))
        colors[0] = [0, 0, 0, 0]  # –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
        transparent_hot = LinearSegmentedColormap.from_list('transparent_hot', colors)

        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç—Ä–µ—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π
        planes = [
            ('Axial (Z)', mid_slice, lambda x: x[mid_slice, :, :]),
            ('Coronal (Y)', mid_slice, lambda x: x[:, mid_slice, :]),
            ('Sagittal (X)', mid_slice, lambda x: x[:, :, mid_slice])
        ]

        for i, (plane_name, slice_idx, slice_fn) in enumerate(planes):
            # –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            orig_slice = slice_fn(original_normalized)
            axes[0, i].imshow(orig_slice, cmap='gray', vmin=0, vmax=1)
            axes[0, i].set_title(f"{plane_name} - –ò—Å—Ö–æ–¥–Ω–æ–µ")
            axes[0, i].axis('off')

            # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å –Ω–∞–ª–æ–∂–µ–Ω–∏–µ–º
            attr_slice = slice_fn(attr_np)
            mask_slice = slice_fn(mask)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
            masked_attr = np.ma.masked_where(~mask_slice, attr_slice)

            im = axes[1, i].imshow(orig_slice, cmap='gray', vmin=0, vmax=1)
            im2 = axes[1, i].imshow(masked_attr, cmap=transparent_hot,
                                    alpha=alpha, vmin=attr_np.min(), vmax=attr_np.max())

            axes[1, i].set_title(f"{plane_name} - –ê—Ç—Ä–∏–±—É—Ç—ã (–ø–æ—Ä–æ–≥: {threshold})")
            axes[1, i].axis('off')

            # –î–æ–±–∞–≤–ª—è–µ–º colorbar –¥–ª—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            plt.colorbar(im2, ax=axes[1, i], fraction=0.046, pad=0.04)

        plt.suptitle(f"{title}\n(–ø–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ –∞—Ç—Ä–∏–±—É—Ç—ã > {threshold:.1%} –æ—Ç –º–∞–∫—Å–∏–º—É–º–∞)", fontsize=14)
        plt.tight_layout()
        if return_png:
            filename = f"{int(time.time())}_{hash(str(time.time())) % 1000:03d}.png"
            plt.savefig(filename)
            return filename
        plt.show()

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        total_voxels = np.prod(attr_np.shape)
        significant_voxels = np.sum(mask)
        print(f"üìä –ó–Ω–∞—á–∏–º—ã–µ –≤–æ–∫—Å–µ–ª–∏: {significant_voxels}/{total_voxels} ({significant_voxels / total_voxels:.1%})")
        print(f"üìà –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç: {attr_np.max():.4f}, –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π: {attr_np.min():.4f}")

    def _visualize_3d_attributions(self, attributions, title="Attributions"):
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –ø–æ –æ—Å—è–º (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)."""
        attr_np = attributions.squeeze().detach().cpu().numpy()

        mid_slice = attr_np.shape[0] // 2

        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # Axial (Z)
        im1 = axes[0].imshow(attr_np[mid_slice, :, :], cmap='hot', vmin=attr_np.min(), vmax=attr_np.max())
        axes[0].set_title("Axial (Z)")
        plt.colorbar(im1, ax=axes[0])

        # Coronal (Y)
        im2 = axes[1].imshow(attr_np[:, mid_slice, :], cmap='hot', vmin=attr_np.min(), vmax=attr_np.max())
        axes[1].set_title("Coronal (Y)")
        plt.colorbar(im2, ax=axes[1])

        # Sagittal (X)
        im3 = axes[2].imshow(attr_np[:, :, mid_slice], cmap='hot', vmin=attr_np.min(), vmax=attr_np.max())
        axes[2].set_title("Sagittal (X)")
        plt.colorbar(im3, ax=axes[2])

        plt.suptitle(title)
        plt.tight_layout()
        plt.show()

    def predict_with_explanation(self, input_tensor: torch.Tensor, method: str = "saliency",
                                 threshold: float = 0.1, alpha: float = 0.7):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–∞ —Ä–∞–∑.

        Returns:
            dict: {'prediction': ..., 'explanation': ...}
        """
        prediction = self.predict(input_tensor)
        explanation = self.explain_prediction(
            input_tensor,
            target_class=prediction['prediction'],
            method=method,
            threshold=threshold,
            alpha=alpha
        )
        return {
            'prediction': prediction,
            'explanation': explanation
        }

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    def predict_batch(self, batch_tensor: torch.Tensor) -> List[Dict[str, Union[float, int, np.ndarray]]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –±–∞—Ç—á–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤."""
        with torch.no_grad():
            batch_size = batch_tensor.shape[0]
            batch_tensor = self._validate_input_tensor(batch_tensor)

            if self._half_precision:
                with torch.cuda.amp.autocast():
                    logits = self.model(batch_tensor)
            else:
                logits = self.model(batch_tensor)

            probabilities = F.softmax(logits, dim=1)
            predicted_classes = torch.argmax(probabilities, dim=1)
            confidences = torch.max(probabilities, dim=1)[0]

            logits_np = logits.cpu().numpy()
            probabilities_np = probabilities.cpu().numpy()

            results = []
            for i in range(batch_size):
                results.append({
                    'prediction': int(predicted_classes[i].item()),
                    'probabilities': probabilities_np[i],
                    'confidence': float(confidences[i].item()),
                    'logits': logits_np[i]
                })

            return results

    def predict_probability(self, input_tensor: torch.Tensor) -> np.ndarray:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤."""
        result = self.predict(input_tensor)
        return result['probabilities']

    def predict_class(self, input_tensor: torch.Tensor) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å."""
        result = self.predict(input_tensor)
        return result['prediction']


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    from config import ModelConfig

    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    config = ModelConfig()
    config.input_D = 256
    config.input_H = 256
    config.input_W = 256
    config.n_seg_classes = 2  # –ø—Ä–∏–º–µ—Ä –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

    # –°–æ–∑–¥–∞–µ–º inference –º–æ–¥—É–ª—å
    inference = MedicalModelInference(
        weights_path="model\\outputs\\weights\\best-epoch=42-val_f1=0.7650-val_auroc=0.8675.ckpt",
        model_config=config
    )

    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä 256x256x256
    test_tensor = torch.randn(1, 1, 256, 256, 256)

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    result = inference.predict(test_tensor)

    print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {result['prediction']}")
    print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.4f}")

    # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    try:
        explanation = inference.explain_prediction(
            test_tensor,
            method="saliency",
            visualize=True,
            threshold=0.2,  # –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ—Ä–æ–≥ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            alpha=0.6  # –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å
        )

        # –ò–ª–∏ –∑–∞ —Ä–∞–∑:
        full_result = inference.predict_with_explanation(
            test_tensor,
            method="saliency",
            threshold=0.2,
            alpha=0.6
        )
        print(f"–ü–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {full_result['prediction']['prediction']}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–∏: {e}")
        print("üîÑ –ü—Ä–æ–±—É–µ–º —Å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º...")

        # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–º –ø–æ—Ä–æ–≥–æ–º
        explanation = inference.explain_prediction(
            test_tensor,
            method="saliency",
            visualize=True,
            threshold=0.3,  # –ë–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥
            alpha=0.5
        )