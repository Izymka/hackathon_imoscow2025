# main.py
import os
import sys
import argparse
import warnings
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import torch
import torch.nn.functional as F
import pytorch_lightning as pl
from torch.utils.data import DataLoader
from pytorch_lightning.callbacks import (
    ModelCheckpoint,
    EarlyStopping,
    LearningRateMonitor,
    RichProgressBar,
    RichModelSummary
)
from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger
from omegaconf import OmegaConf
from sklearn.model_selection import StratifiedKFold, train_test_split
import pandas as pd
import numpy as np
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich import print as rprint

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# === –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã ===
from datasets.medical_tensors import MedicalTensorDataset
from model_generator import generate_model
from lightning_module import MedicalClassificationModel
from config import ModelConfig

# === MONAI –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ===
from monai.transforms import (
    Compose,
    RandFlip,
    RandRotate90,
    RandGaussianNoise,
    RandShiftIntensity,
    RandAdjustContrast,
    RandScaleIntensity,
    CropForeground,
    SpatialPad,
    EnsureChannelFirst,
    Orientation,
    ToTensor
)

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings("ignore", category=UserWarning)

console = Console()


def get_safe_train_transforms(input_size: Tuple[int, int, int]) -> Compose:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö 3D –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    –°–æ—Ö—Ä–∞–Ω—è—é—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö.
    """
    return Compose([
        #EnsureChannelFirst(),

        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ)
        RandFlip(prob=0.3, spatial_axis=0),  # —Ç–æ–ª—å–∫–æ –ø–æ –æ–¥–Ω–æ–π –æ—Å–∏
        RandRotate90(prob=0.2, max_k=1, spatial_axes=(1, 2)),  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–∞—â–µ–Ω–∏–µ

        # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (—Å–ª–∞–±—ã–µ)
        RandGaussianNoise(prob=0.15, std=0.005),  # –æ—á–µ–Ω—å —Å–ª–∞–±—ã–π —à—É–º
        RandShiftIntensity(offsets=0.05, prob=0.2),  # —Å–¥–≤–∏–≥ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏
        RandAdjustContrast(gamma=(0.9, 1.1), prob=0.2),  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        RandScaleIntensity(factors=(-0.05, 0.05), prob=0.2),  # –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

        #ToTensor(),
    ])


def get_val_transforms() -> Compose:
    """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)."""
    return Compose([
        #EnsureChannelFirst(),
        #ToTensor(),
    ])


class CrossValidationTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏."""

    def __init__(self, cfg: OmegaConf, cfg_namespace: argparse.Namespace):
        self.cfg = cfg
        self.cfg_namespace = cfg_namespace
        self.results = []

    def load_data_labels(self) -> Tuple[List[str], List[int]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –∏ –º–µ—Ç–∫–∏ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏."""
        labels_df = pd.read_csv(self.cfg.img_list)

        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ CSV: filename, label
        if 'filename' not in labels_df.columns or 'label' not in labels_df.columns:
            raise ValueError("CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'filename' –∏ 'label'")

        filenames = labels_df['filename'].tolist()
        labels = labels_df['label'].tolist()

        return filenames, labels

    def create_fold_datasets(self, train_indices: List[int], val_indices: List[int],
                             filenames: List[str], labels: List[int]) -> Tuple[DataLoader, DataLoader]:
        """–°–æ–∑–¥–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç—ã –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–ª—è —Ñ–æ–ª–¥–∞."""

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ CSV —Ñ–∞–π–ª—ã –¥–ª—è —Ñ–æ–ª–¥–∞
        train_data = [(filenames[i], labels[i]) for i in train_indices]
        val_data = [(filenames[i], labels[i]) for i in val_indices]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        train_df = pd.DataFrame(train_data, columns=['filename', 'label'])
        val_df = pd.DataFrame(val_data, columns=['filename', 'label'])

        fold_train_path = f"temp_train_fold.csv"
        fold_val_path = f"temp_val_fold.csv"

        train_df.to_csv(fold_train_path, index=False)
        val_df.to_csv(fold_val_path, index=False)

        # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
        train_dataset = MedicalTensorDataset(
            self.cfg.data_root,
            fold_train_path,
            self.cfg_namespace,
            transform=get_safe_train_transforms((self.cfg.input_D, self.cfg.input_H, self.cfg.input_W))
        )

        val_dataset = MedicalTensorDataset(
            self.cfg.data_root,
            fold_val_path,
            self.cfg_namespace,
            transform=get_val_transforms()
        )

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã DataLoader
        num_workers = 0 if self.cfg.ci_test else min(0, os.cpu_count())

        train_loader = DataLoader(
            train_dataset,
            batch_size=self.cfg.batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=self.cfg_namespace.pin_memory and torch.cuda.is_available(),
            persistent_workers=num_workers > 0,
            drop_last=True
        )

        val_loader = DataLoader(
            val_dataset,
            batch_size=self.cfg.batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=self.cfg_namespace.pin_memory and torch.cuda.is_available(),
            persistent_workers=num_workers > 0
        )

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        os.remove(fold_train_path)
        os.remove(fold_val_path)

        return train_loader, val_loader

    def train_fold(self, fold: int, train_loader: DataLoader, val_loader: DataLoader) -> Dict:
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –æ–¥–Ω–æ–º —Ñ–æ–ª–¥–µ."""

        rprint(f"\nüìÑ [bold blue]–û–±—É—á–µ–Ω–∏–µ —Ñ–æ–ª–¥–∞ {fold + 1}/{self.cfg.n_splits}[/bold blue]")

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Ñ–æ–ª–¥–∞
        model, parameters = generate_model(self.cfg_namespace)

        # –ù–ï –ø–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –≤—Ä—É—á–Ω—É—é - Lightning —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        device_name = 'GPU' if torch.cuda.is_available() and not self.cfg.no_cuda else 'CPU'
        print(f"‚úÖ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {device_name}")

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ CPU
        class_weights = self.calculate_class_weights(train_loader)

        lightning_model = MedicalClassificationModel(
            model,
            learning_rate=self.cfg.learning_rate,
            num_classes=self.cfg.n_seg_classes,
            use_weighted_loss=True,
            class_weights=class_weights,
        )
        if device_name == 'GPU':
            lightning_model = lightning_model.to('cuda')
            print("Switched device: ", lightning_model.device)

        # –õ–æ–≥–≥–µ—Ä—ã –¥–ª—è —Ñ–æ–ª–¥–∞
        fold_name = f"medical_classification_fold_{fold + 1}"
        tb_logger = TensorBoardLogger("tb_logs", name=fold_name, version=f"fold_{fold + 1}")
        csv_logger = CSVLogger("logs", name=fold_name, version=f"fold_{fold + 1}")

        # –ö–æ–ª–ª–±—ç–∫–∏
        checkpoint_callback = ModelCheckpoint(
            dirpath=f"{self.cfg.save_folder}/fold_{fold + 1}",
            filename="best-{epoch:02d}-{val_f1:.4f}-{val_recall:.4f}-{val_specificity:.4f}--{val_auroc:.4f}",
            save_top_k=-1,
            every_n_epochs=1,
            monitor=self.cfg.monitor_metric,
            mode=self.cfg.checkpoint_mode,
            save_weights_only=False,
            verbose=False
        )

        early_stopping = EarlyStopping(
            monitor=self.cfg.early_stopping_metric,
            min_delta=self.cfg.early_stopping_min_delta,
            patience=self.cfg.early_stopping_patience,
            verbose=False,
            mode=self.cfg.checkpoint_mode
        )

        lr_monitor = LearningRateMonitor(logging_interval='epoch')

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ accelerator
        if self.cfg.no_cuda or not torch.cuda.is_available():
            accelerator = "cpu"
            devices = 1
        else:
            accelerator = "gpu"
            devices = 1

        # –°–æ–∑–¥–∞–µ–º trainer
        trainer = pl.Trainer(
            max_epochs=self.cfg.n_epochs,
            logger=[tb_logger, csv_logger],
            callbacks=[
                checkpoint_callback,
                early_stopping,
                lr_monitor,
                RichProgressBar(),
            ],
            accelerator=accelerator,
            devices=devices,
            accumulate_grad_batches=getattr(self.cfg, 'accumulate_grad_batches', 1),  # Gradient accumulation
            fast_dev_run=self.cfg.ci_test,
            log_every_n_steps=min(10, len(train_loader) // 4),
            enable_progress_bar=True,
            enable_model_summary=True,
            gradient_clip_val=self.cfg.gradient_clip_val,
            precision=32,
        )

        # –û–±—É—á–µ–Ω–∏–µ
        trainer.fit(lightning_model, train_loader, val_loader)

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        best_metrics = checkpoint_callback.best_model_score.item()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        best_model = MedicalClassificationModel.load_from_checkpoint(
            checkpoint_callback.best_model_path,
            model=model,
            learning_rate=self.cfg.learning_rate,
            num_classes=self.cfg.n_seg_classes
        )

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        trainer.validate(best_model, val_loader, verbose=False)

        fold_results = {
            'fold': fold + 1,
            'best_val_score': best_metrics,
            'best_checkpoint': checkpoint_callback.best_model_path,
            'final_epoch': trainer.current_epoch,
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if hasattr(best_model, 'validation_metrics'):
            fold_results.update(best_model.validation_metrics)

        return fold_results

    def calculate_class_weights(self, train_loader: DataLoader) -> torch.Tensor:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å."""
        class_counts = torch.zeros(self.cfg.n_seg_classes, dtype=torch.float32)

        for batch in train_loader:
            _, labels = batch
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ CPU –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
            labels = labels.cpu() if isinstance(labels, torch.Tensor) else labels
            for label in labels:
                label_val = int(label.item()) if hasattr(label, 'item') else int(label)
                class_counts[label_val] += 1

        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã
        total_samples = class_counts.sum()
        class_weights = total_samples / (self.cfg.n_seg_classes * class_counts)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        class_weights = class_weights / class_weights.sum() * self.cfg.n_seg_classes

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å–∞ –Ω–∞ CPU
        return class_weights.cpu()

    def run_cross_validation(self) -> Dict:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é (–∏–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–π —Ñ–æ–ª–¥ –ø—Ä–∏ n_splits=1)."""

        console.print(Panel.fit(
            "[bold green]üè• –ú–ï–î–ò–¶–ò–ù–°–ö–ê–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø - –û–ë–£–ß–ï–ù–ò–ï üè•[/bold green]",
            border_style="green"
        ))

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        filenames, labels = self.load_data_labels()
        unique_labels, counts = np.unique(labels, return_counts=True)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
        data_table = Table(title="üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
        data_table.add_column("–ü–∞—Ä–∞–º–µ—Ç—Ä", style="cyan")
        data_table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="yellow")
        data_table.add_row("–í—Å–µ–≥–æ –æ–±—Ä–∞–∑—Ü–æ–≤", str(len(filenames)))
        for label, count in zip(unique_labels, counts):
            data_table.add_row(f"–ö–ª–∞—Å—Å {label}", f"{count} ({count / len(labels) * 100:.1f}%)")
        console.print(data_table)

        all_results = []

        if self.cfg.n_splits == 1:
            # –û–¥–∏–Ω —Ñ–æ–ª–¥ = –æ–¥–∏–Ω train/val split
            train_idx, val_idx = train_test_split(
                np.arange(len(filenames)),
                test_size=self.cfg.val_size if hasattr(self.cfg, "val_size") else 0.2,
                stratify=labels,
                random_state=self.cfg.cv_random_state
            )
            folds = [(train_idx, val_idx)]
        else:
            skf = StratifiedKFold(
                n_splits=self.cfg.n_splits,
                shuffle=True,
                random_state=self.cfg.cv_random_state
            )
            folds = skf.split(filenames, labels)

        # –û–±—É—á–µ–Ω–∏–µ –ø–æ —Ñ–æ–ª–¥–∞–º
        for fold, (train_indices, val_indices) in enumerate(folds):
            train_loader, val_loader = self.create_fold_datasets(
                train_indices, val_indices, filenames, labels
            )
            fold_results = self.train_fold(fold, train_loader, val_loader)
            all_results.append(fold_results)

            rprint(f"‚úÖ [bold green]–§–æ–ª–¥ {fold + 1} –∑–∞–≤–µ—Ä—à–µ–Ω![/bold green]")
            rprint(f"   üìà –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {fold_results['best_val_score']:.4f}")

        # –°–≤–æ–¥–∫–∞ (–µ—Å–ª–∏ —Ñ–æ–ª–¥–æ–≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ)
        if len(all_results) > 1:
            self.print_cv_summary(all_results)

        return {
            'fold_results': all_results,
            'cv_summary': self.calculate_cv_summary(all_results) if len(all_results) > 1 else all_results[0]
        }

    def calculate_cv_summary(self, results: List[Dict]) -> Dict:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏."""
        scores = [r['best_val_score'] for r in results]

        return {
            'mean_score': np.mean(scores),
            'std_score': np.std(scores),
            'min_score': np.min(scores),
            'max_score': np.max(scores),
            'median_score': np.median(scores)
        }

    def print_cv_summary(self, results: List[Dict]):
        """–í—ã–≤–æ–¥–∏—Ç –∫—Ä–∞—Å–∏–≤—É—é —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏."""

        summary_table = Table(title="üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–†–û–°–°-–í–ê–õ–ò–î–ê–¶–ò–ò")
        summary_table.add_column("–§–æ–ª–¥", style="cyan", justify="center")
        summary_table.add_column("–õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç", style="yellow", justify="center")
        summary_table.add_column("–§–∏–Ω–∞–ª—å–Ω–∞—è —ç–ø–æ—Ö–∞", style="blue", justify="center")

        scores = []
        for result in results:
            summary_table.add_row(
                str(result['fold']),
                f"{result['best_val_score']:.4f}",
                str(result['final_epoch'])
            )
            scores.append(result['best_val_score'])

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        summary_table.add_row("---", "---", "---", style="dim")
        summary_table.add_row(
            "–°–†–ï–î–ù–ï–ï",
            f"{np.mean(scores):.4f} ¬± {np.std(scores):.4f}",
            "",
            style="bold green"
        )

        console.print(summary_table)

        # –ü–∞–Ω–µ–ª—å —Å –∏—Ç–æ–≥–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        summary_text = f"""
[bold green]üìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:[/bold green]
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {np.mean(scores):.4f} ¬± {np.std(scores):.4f}
‚Ä¢ –õ—É—á—à–∏–π —Ñ–æ–ª–¥: {np.max(scores):.4f}
‚Ä¢ –•—É–¥—à–∏–π —Ñ–æ–ª–¥: {np.min(scores):.4f}
‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞: {np.median(scores):.4f}
‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏: {(np.std(scores) / np.mean(scores) * 100):.2f}%
        """

        console.print(Panel(summary_text, title="üèÜ –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç", border_style="green"))


def setup_environment(cfg: OmegaConf) -> argparse.Namespace:
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."""

    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    torch.manual_seed(cfg.manual_seed)
    np.random.seed(cfg.manual_seed)

    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    Path(cfg.save_folder).mkdir(parents=True, exist_ok=True)
    Path("tb_logs").mkdir(exist_ok=True)
    Path("logs").mkdir(exist_ok=True)

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ namespace
    cfg_dict = OmegaConf.to_container(cfg)
    cfg_dict['gpu_id'] = [] if cfg.no_cuda else [0]
    cfg_dict['phase'] = 'train'
    cfg_dict['pin_memory'] = not cfg.no_cuda and torch.cuda.is_available()

    # –û—Ç–∫–ª—é—á–∞–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    torch.use_deterministic_algorithms(False)

    return argparse.Namespace(**cfg_dict)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è."""

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞
        cfg = ModelConfig()
        cfg = OmegaConf.structured(cfg)

        # CLI –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        cli_cfg = OmegaConf.from_cli()
        cfg = OmegaConf.merge(cfg, cli_cfg)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è CI —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if cfg.ci_test:
            cfg.img_list = '../toy_data/test_ci.txt'
            cfg.n_epochs = 2
            cfg.no_cuda = True
            cfg.data_root = '../toy_data'
            cfg.pretrain_path = ''
            cfg.num_workers = 0
            cfg.batch_size = 2
            cfg.n_splits = 2

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        cfg_namespace = setup_environment(cfg)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
        device_info = "CPU" if cfg.no_cuda else f"GPU ({torch.cuda.get_device_name()})" if torch.cuda.is_available() else "CPU (CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)"

        system_table = Table(title="üíª –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ")
        system_table.add_column("–ü–∞—Ä–∞–º–µ—Ç—Ä", style="cyan")
        system_table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="yellow")

        system_table.add_row("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ", device_info)
        system_table.add_row("PyTorch –≤–µ—Ä—Å–∏—è", torch.__version__)
        system_table.add_row("CUDA –¥–æ—Å—Ç—É–ø–Ω–∞", str(torch.cuda.is_available()))
        system_table.add_row("–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞", str(cfg.batch_size))
        system_table.add_row("Learning rate", str(cfg.learning_rate))
        system_table.add_row("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤", str(cfg.n_splits))
        system_table.add_row("–ú–∞–∫—Å–∏–º—É–º —ç–ø–æ—Ö", str(cfg.n_epochs))

        console.print(system_table)

        # –ó–∞–ø—É—Å–∫ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
        cv_trainer = CrossValidationTrainer(cfg, cfg_namespace)
        results = cv_trainer.run_cross_validation()

        rprint("\nüéâ [bold green]–û–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ![/bold green]")

        return results

    except Exception as e:
        rprint(f"\n‚ùå [bold red]–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:[/bold red] {str(e)}")
        console.print_exception(show_locals=True)
        return None

if __name__ == '__main__':
    main()
        