# main.py
import os
import sys
import argparse
import warnings
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import torch
import torch.nn.functional as F
import pytorch_lightning as pl
from torch.utils.data import DataLoader
from pytorch_lightning.callbacks import (
    ModelCheckpoint,
    EarlyStopping,
    LearningRateMonitor,
    RichProgressBar,
    RichModelSummary
)
from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger
from omegaconf import OmegaConf
from sklearn.model_selection import StratifiedKFold
import pandas as pd
import numpy as np
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich import print as rprint

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# === Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ ===
from datasets.medical_tensors import MedicalTensorDataset
from model_generator import generate_model
from lightning_module import MedicalClassificationModel
from config import ModelConfig
from inference import MedicalModelInference

# === MONAI Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ ===
from monai.transforms import (
    Compose,
    RandFlip,
    RandRotate90,
    RandGaussianNoise,
    RandShiftIntensity,
    RandAdjustContrast,
    RandScaleIntensity,
    CropForeground,
    SpatialPad,
    EnsureChannelFirst,
    Orientation,
    ToTensor
)

# ÐŸÐ¾Ð´Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ
warnings.filterwarnings("ignore", category=UserWarning)

console = Console()


def get_safe_train_transforms(input_size: Tuple[int, int, int]) -> Compose:
    """
    Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ðµ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ñ… 3D Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹.
    Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÑŽÑ‚ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ñ….
    """
    return Compose([
        #EnsureChannelFirst(),

        # ÐŸÑ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ (ÐºÐ¾Ð½ÑÐµÑ€Ð²Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ)
        RandFlip(prob=0.3, spatial_axis=0),  # Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¹ Ð¾ÑÐ¸
        RandRotate90(prob=0.2, max_k=1, spatial_axes=(1, 2)),  # Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð²Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ

        # Ð˜Ð½Ñ‚ÐµÐ½ÑÐ¸Ð²Ð½Ð¾ÑÑ‚Ð½Ñ‹Ðµ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ (ÑÐ»Ð°Ð±Ñ‹Ðµ)
        RandGaussianNoise(prob=0.15, std=0.005),  # Ð¾Ñ‡ÐµÐ½ÑŒ ÑÐ»Ð°Ð±Ñ‹Ð¹ ÑˆÑƒÐ¼
        RandShiftIntensity(offsets=0.05, prob=0.2),  # ÑÐ´Ð²Ð¸Ð³ Ð¸Ð½Ñ‚ÐµÐ½ÑÐ¸Ð²Ð½Ð¾ÑÑ‚Ð¸
        RandAdjustContrast(gamma=(0.9, 1.1), prob=0.2),  # Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ†Ð¸Ñ ÐºÐ¾Ð½Ñ‚Ñ€Ð°ÑÑ‚Ð°
        RandScaleIntensity(factors=(-0.05, 0.05), prob=0.2),  # Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ

        #ToTensor(),
    ])


def get_val_transforms() -> Compose:
    """Ð¢Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸ (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ)."""
    return Compose([
        #EnsureChannelFirst(),
        #ToTensor(),
    ])


class CrossValidationTrainer:
    """ÐšÐ»Ð°ÑÑ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸Ñ ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸."""

    def __init__(self, cfg: OmegaConf, cfg_namespace: argparse.Namespace):
        self.cfg = cfg
        self.cfg_namespace = cfg_namespace
        self.results = []

    def load_data_labels(self) -> Tuple[List[str], List[int]]:
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð¿ÑƒÑ‚Ð¸ Ðº Ñ„Ð°Ð¹Ð»Ð°Ð¼ Ð¸ Ð¼ÐµÑ‚ÐºÐ¸ Ð´Ð»Ñ ÑÑ‚Ñ€Ð°Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸."""
        labels_df = pd.read_csv(self.cfg.img_list)

        # ÐŸÑ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° CSV: filename, label
        if 'filename' not in labels_df.columns or 'label' not in labels_df.columns:
            raise ValueError("CSV Ð´Ð¾Ð»Ð¶ÐµÐ½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ 'filename' Ð¸ 'label'")

        filenames = labels_df['filename'].tolist()
        labels = labels_df['label'].tolist()

        return filenames, labels

    def create_fold_datasets(self, train_indices: List[int], val_indices: List[int],
                             filenames: List[str], labels: List[int]) -> Tuple[DataLoader, DataLoader]:
        """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹ Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·Ñ‡Ð¸ÐºÐ¸ Ð´Ð»Ñ Ñ„Ð¾Ð»Ð´Ð°."""

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ CSV Ñ„Ð°Ð¹Ð»Ñ‹ Ð´Ð»Ñ Ñ„Ð¾Ð»Ð´Ð°
        train_data = [(filenames[i], labels[i]) for i in train_indices]
        val_data = [(filenames[i], labels[i]) for i in val_indices]

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
        train_df = pd.DataFrame(train_data, columns=['filename', 'label'])
        val_df = pd.DataFrame(val_data, columns=['filename', 'label'])

        fold_train_path = f"temp_train_fold.csv"
        fold_val_path = f"temp_val_fold.csv"

        train_df.to_csv(fold_train_path, index=False)
        val_df.to_csv(fold_val_path, index=False)

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹
        train_dataset = MedicalTensorDataset(
            self.cfg.data_root,
            fold_train_path,
            self.cfg_namespace,
            transform=get_safe_train_transforms((self.cfg.input_D, self.cfg.input_H, self.cfg.input_W))
        )

        val_dataset = MedicalTensorDataset(
            self.cfg.data_root,
            fold_val_path,
            self.cfg_namespace,
            transform=get_val_transforms()
        )

        # ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ DataLoader
        num_workers = 0 if self.cfg.ci_test else min(0, os.cpu_count())

        train_loader = DataLoader(
            train_dataset,
            batch_size=self.cfg.batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=self.cfg_namespace.pin_memory and torch.cuda.is_available(),
            persistent_workers=num_workers > 0,
            drop_last=True
        )

        val_loader = DataLoader(
            val_dataset,
            batch_size=self.cfg.batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=self.cfg_namespace.pin_memory and torch.cuda.is_available(),
            persistent_workers=num_workers > 0
        )

        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
        os.remove(fold_train_path)
        os.remove(fold_val_path)

        return train_loader, val_loader

    def train_fold(self, fold: int, train_loader: DataLoader, val_loader: DataLoader) -> Dict:
        """ÐžÐ±ÑƒÑ‡Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ð° Ð¾Ð´Ð½Ð¾Ð¼ Ñ„Ð¾Ð»Ð´Ðµ."""

        rprint(f"\nðŸ“„ [bold blue]ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ„Ð¾Ð»Ð´Ð° {fold + 1}/{self.cfg.n_splits}[/bold blue]")

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ñ„Ð¾Ð»Ð´Ð°
        model, parameters = generate_model(self.cfg_namespace)

        # ÐÐ• Ð¿ÐµÑ€ÐµÐ¼ÐµÑ‰Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ - Lightning ÑÐ´ÐµÐ»Ð°ÐµÑ‚ ÑÑ‚Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸
        device_name = 'GPU' if torch.cuda.is_available() and not self.cfg.no_cuda else 'CPU'
        print(f"âœ… Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ: {device_name}")

        # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•: Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð²ÐµÑÐ° ÐºÐ»Ð°ÑÑÐ¾Ð² Ð½Ð° CPU
        class_weights = self.calculate_class_weights(train_loader)

        lightning_model = MedicalClassificationModel(
            model,
            learning_rate=self.cfg.learning_rate,
            num_classes=self.cfg.n_seg_classes,
            use_weighted_loss=True,
            class_weights=class_weights  # Lightning Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿ÐµÑ€ÐµÐ¼ÐµÑÑ‚Ð¸Ñ‚ Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ðµ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾
        )

        # Ð›Ð¾Ð³Ð³ÐµÑ€Ñ‹ Ð´Ð»Ñ Ñ„Ð¾Ð»Ð´Ð°
        fold_name = f"medical_classification_fold_{fold + 1}"
        tb_logger = TensorBoardLogger("tb_logs", name=fold_name, version=f"fold_{fold + 1}")
        csv_logger = CSVLogger("logs", name=fold_name, version=f"fold_{fold + 1}")

        # ÐšÐ¾Ð»Ð»Ð±ÑÐºÐ¸
        checkpoint_callback = ModelCheckpoint(
            dirpath=f"{self.cfg.save_folder}/fold_{fold + 1}",
            filename="best-{epoch:02d}-{val_f1:.4f}-{val_auroc:.4f}",
            save_top_k=2,
            monitor=self.cfg.monitor_metric,
            mode=self.cfg.checkpoint_mode,
            save_weights_only=False,
            verbose=False
        )

        early_stopping = EarlyStopping(
            monitor=self.cfg.early_stopping_metric,
            min_delta=self.cfg.early_stopping_min_delta,
            patience=self.cfg.early_stopping_patience,
            verbose=False,
            mode=self.cfg.checkpoint_mode
        )

        lr_monitor = LearningRateMonitor(logging_interval='epoch')

        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° accelerator
        if self.cfg.no_cuda or not torch.cuda.is_available():
            accelerator = "cpu"
            devices = 1
        else:
            accelerator = "gpu"
            devices = 1

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ trainer
        trainer = pl.Trainer(
            max_epochs=self.cfg.n_epochs,
            logger=[tb_logger, csv_logger],
            callbacks=[
                checkpoint_callback,
                early_stopping,
                lr_monitor,
                RichProgressBar(),
            ],
            accelerator=accelerator,
            devices=devices,
            fast_dev_run=self.cfg.ci_test,
            log_every_n_steps=min(10, len(train_loader) // 4),
            enable_progress_bar=True,
            enable_model_summary=True,
            gradient_clip_val=self.cfg.gradient_clip_val,
            precision=16 if accelerator == "gpu" else 32,  # mixed precision
        )

        # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
        trainer.fit(lightning_model, train_loader, val_loader)

        # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        best_metrics = checkpoint_callback.best_model_score.item()

        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð»ÑƒÑ‡ÑˆÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        best_model = MedicalClassificationModel.load_from_checkpoint(
            checkpoint_callback.best_model_path,
            model=model,
            learning_rate=self.cfg.learning_rate,
            num_classes=self.cfg.n_seg_classes
        )

        # Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð½Ð° Ð»ÑƒÑ‡ÑˆÐµÐ¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        trainer.validate(best_model, val_loader, verbose=False)

        fold_results = {
            'fold': fold + 1,
            'best_val_score': best_metrics,
            'best_checkpoint': checkpoint_callback.best_model_path,
            'final_epoch': trainer.current_epoch,
        }

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð²ÑÐµ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        if hasattr(best_model, 'validation_metrics'):
            fold_results.update(best_model.validation_metrics)

        return fold_results

    def calculate_class_weights(self, train_loader: DataLoader) -> torch.Tensor:
        """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ Ð²ÐµÑÐ° ÐºÐ»Ð°ÑÑÐ¾Ð² Ð´Ð»Ñ ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð¿Ð¾Ñ‚ÐµÑ€ÑŒ."""
        class_counts = torch.zeros(self.cfg.n_seg_classes)

        for batch in train_loader:
            _, labels = batch
            for label in labels:
                class_counts[int(label.item())] += 1

        # Ð˜Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹
        total_samples = class_counts.sum()
        class_weights = total_samples / (self.cfg.n_seg_classes * class_counts)

        # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
        class_weights = class_weights / class_weights.sum() * self.cfg.n_seg_classes

        return class_weights

    def run_cross_validation(self) -> Dict:
        """Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ Ð¿Ð¾Ð»Ð½ÑƒÑŽ ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÑŽ."""

        # ÐšÑ€Ð°ÑÐ¸Ð²Ñ‹Ð¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
        console.print(Panel.fit(
            "[bold green]ðŸ¥ ÐœÐ•Ð”Ð˜Ð¦Ð˜ÐÐ¡ÐšÐÐ¯ ÐšÐ›ÐÐ¡Ð¡Ð˜Ð¤Ð˜ÐšÐÐ¦Ð˜Ð¯ - ÐšÐ ÐžÐ¡Ð¡-Ð’ÐÐ›Ð˜Ð”ÐÐ¦Ð˜Ð¯ ðŸ¥[/bold green]",
            border_style="green"
        ))

        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        filenames, labels = self.load_data_labels()

        # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        unique_labels, counts = np.unique(labels, return_counts=True)

        data_table = Table(title="ðŸ“Š Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
        data_table.add_column("ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€", style="cyan")
        data_table.add_column("Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ", style="yellow")

        data_table.add_row("Ð’ÑÐµÐ³Ð¾ Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð¾Ð²", str(len(filenames)))
        for label, count in zip(unique_labels, counts):
            data_table.add_row(f"ÐšÐ»Ð°ÑÑ {label}", f"{count} ({count / len(labels) * 100:.1f}%)")

        console.print(data_table)

        # Ð¡Ñ‚Ñ€Ð°Ñ‚Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
        skf = StratifiedKFold(
            n_splits=self.cfg.n_splits,
            shuffle=True,
            random_state=self.cfg.cv_random_state
        )

        all_results = []

        # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ñ„Ð¾Ð»Ð´Ð°Ð¼
        for fold, (train_indices, val_indices) in enumerate(skf.split(filenames, labels)):
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹ Ð´Ð»Ñ Ñ„Ð¾Ð»Ð´Ð°
            train_loader, val_loader = self.create_fold_datasets(
                train_indices, val_indices, filenames, labels
            )

            # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ñ„Ð¾Ð»Ð´Ðµ
            train_labels = [labels[i] for i in train_indices]
            val_labels = [labels[i] for i in val_indices]

            fold_table = Table(title=f"ðŸ“‹ Ð¤Ð¾Ð»Ð´ {fold + 1}")
            fold_table.add_column("ÐÐ°Ð±Ð¾Ñ€", style="cyan")
            fold_table.add_column("Ð Ð°Ð·Ð¼ÐµÑ€", style="yellow")
            fold_table.add_column("ÐšÐ»Ð°ÑÑ 0", style="red")
            fold_table.add_column("ÐšÐ»Ð°ÑÑ 1", style="green")

            train_counts = np.bincount(train_labels)
            val_counts = np.bincount(val_labels)

            fold_table.add_row(
                "ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ",
                str(len(train_indices)),
                f"{train_counts[0]} ({train_counts[0] / len(train_indices) * 100:.1f}%)",
                f"{train_counts[1]} ({train_counts[1] / len(train_indices) * 100:.1f}%)"
            )
            fold_table.add_row(
                "Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ",
                str(len(val_indices)),
                f"{val_counts[0]} ({val_counts[0] / len(val_indices) * 100:.1f}%)",
                f"{val_counts[1]} ({val_counts[1] / len(val_indices) * 100:.1f}%)"
            )

            console.print(fold_table)

            # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ„Ð¾Ð»Ð´Ð°
            fold_results = self.train_fold(fold, train_loader, val_loader)
            all_results.append(fold_results)

            # ÐŸÑ€Ð¾Ð¼ÐµÐ¶ÑƒÑ‚Ð¾Ñ‡Ð½Ñ‹Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
            rprint(f"âœ… [bold green]Ð¤Ð¾Ð»Ð´ {fold + 1} Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½![/bold green]")
            rprint(f"   ðŸ“ˆ Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {fold_results['best_val_score']:.4f}")

        # Ð¡Ð²Ð¾Ð´ÐºÐ° Ð¿Ð¾ Ð²ÑÐµÐ¼ Ñ„Ð¾Ð»Ð´Ð°Ð¼
        self.print_cv_summary(all_results)

        return {
            'fold_results': all_results,
            'cv_summary': self.calculate_cv_summary(all_results)
        }

    def calculate_cv_summary(self, results: List[Dict]) -> Dict:
        """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÑÐ²Ð¾Ð´Ð½ÑƒÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸."""
        scores = [r['best_val_score'] for r in results]

        return {
            'mean_score': np.mean(scores),
            'std_score': np.std(scores),
            'min_score': np.min(scores),
            'max_score': np.max(scores),
            'median_score': np.median(scores)
        }

    def print_cv_summary(self, results: List[Dict]):
        """Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ ÐºÑ€Ð°ÑÐ¸Ð²ÑƒÑŽ ÑÐ²Ð¾Ð´ÐºÑƒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸."""

        summary_table = Table(title="ðŸŽ¯ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐšÐ ÐžÐ¡Ð¡-Ð’ÐÐ›Ð˜Ð”ÐÐ¦Ð˜Ð˜")
        summary_table.add_column("Ð¤Ð¾Ð»Ð´", style="cyan", justify="center")
        summary_table.add_column("Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚", style="yellow", justify="center")
        summary_table.add_column("Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÑÐ¿Ð¾Ñ…Ð°", style="blue", justify="center")

        scores = []
        for result in results:
            summary_table.add_row(
                str(result['fold']),
                f"{result['best_val_score']:.4f}",
                str(result['final_epoch'])
            )
            scores.append(result['best_val_score'])

        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸
        summary_table.add_row("---", "---", "---", style="dim")
        summary_table.add_row(
            "Ð¡Ð Ð•Ð”ÐÐ•Ð•",
            f"{np.mean(scores):.4f} Â± {np.std(scores):.4f}",
            "",
            style="bold green"
        )

        console.print(summary_table)

        # ÐŸÐ°Ð½ÐµÐ»ÑŒ Ñ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹
        summary_text = f"""
[bold green]ðŸ“Š Ð˜Ð¢ÐžÐ“ÐžÐ’Ð«Ð• Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð«:[/bold green]
â€¢ Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {np.mean(scores):.4f} Â± {np.std(scores):.4f}
â€¢ Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ Ñ„Ð¾Ð»Ð´: {np.max(scores):.4f}
â€¢ Ð¥ÑƒÐ´ÑˆÐ¸Ð¹ Ñ„Ð¾Ð»Ð´: {np.min(scores):.4f}
â€¢ ÐœÐµÐ´Ð¸Ð°Ð½Ð°: {np.median(scores):.4f}
â€¢ ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ð¸: {(np.std(scores) / np.mean(scores) * 100):.2f}%
        """

        console.print(Panel(summary_text, title="ðŸ† Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚", border_style="green"))


def setup_environment(cfg: OmegaConf) -> argparse.Namespace:
    """ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÑ‚ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ."""

    # Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° seed Ð´Ð»Ñ Ð²Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸
    torch.manual_seed(cfg.manual_seed)
    np.random.seed(cfg.manual_seed)

    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹
    Path(cfg.save_folder).mkdir(parents=True, exist_ok=True)
    Path("tb_logs").mkdir(exist_ok=True)
    Path("logs").mkdir(exist_ok=True)

    # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² namespace
    cfg_dict = OmegaConf.to_container(cfg)
    cfg_dict['gpu_id'] = [] if cfg.no_cuda else [0]
    cfg_dict['phase'] = 'train'
    cfg_dict['pin_memory'] = not cfg.no_cuda and torch.cuda.is_available()

    # ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð´ÐµÑ‚ÐµÑ€Ð¼Ð¸Ð½Ð¸Ð·Ð¼ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
    torch.use_deterministic_algorithms(False)

    return argparse.Namespace(**cfg_dict)


def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ."""

    try:
        # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐºÐ¾Ð½Ñ„Ð¸Ð³Ð°
        cfg = ModelConfig()
        cfg = OmegaConf.structured(cfg)

        # CLI Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
        cli_cfg = OmegaConf.from_cli()
        cfg = OmegaConf.merge(cfg, cli_cfg)

        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð´Ð»Ñ CI Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        if cfg.ci_test:
            cfg.img_list = '../toy_data/test_ci.txt'
            cfg.n_epochs = 2
            cfg.no_cuda = True
            cfg.data_root = '../toy_data'
            cfg.pretrain_path = ''
            cfg.num_workers = 0
            cfg.batch_size = 2
            cfg.n_splits = 2

        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
        cfg_namespace = setup_environment(cfg)

        # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ
        device_info = "CPU" if cfg.no_cuda else f"GPU ({torch.cuda.get_device_name()})" if torch.cuda.is_available() else "CPU (CUDA Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°)"

        system_table = Table(title="ðŸ’» Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ")
        system_table.add_column("ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€", style="cyan")
        system_table.add_column("Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ", style="yellow")

        system_table.add_row("Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾", device_info)
        system_table.add_row("PyTorch Ð²ÐµÑ€ÑÐ¸Ñ", torch.__version__)
        system_table.add_row("CUDA Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°", str(torch.cuda.is_available()))
        system_table.add_row("Ð Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ñ‚Ñ‡Ð°", str(cfg.batch_size))
        system_table.add_row("Learning rate", str(cfg.learning_rate))
        system_table.add_row("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ„Ð¾Ð»Ð´Ð¾Ð²", str(cfg.n_splits))
        system_table.add_row("ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ ÑÐ¿Ð¾Ñ…", str(cfg.n_epochs))

        console.print(system_table)

        # Ð—Ð°Ð¿ÑƒÑÐº ÐºÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸
        cv_trainer = CrossValidationTrainer(cfg, cfg_namespace)
        results = cv_trainer.run_cross_validation()

        rprint("\nðŸŽ‰ [bold green]ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾![/bold green]")

        return results

    except Exception as e:
        rprint(f"\nâŒ [bold red]ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ:[/bold red] {str(e)}")
        console.print_exception(show_locals=True)
        return None


def adapt_model_for_input_size(model, input_size, model_depth, n_seg_classes):
    """
    ÐÐ´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ð²Ñ…Ð¾Ð´Ð° Ð¿ÑƒÑ‚ÐµÐ¼ Ð·Ð°Ð¼ÐµÐ½Ñ‹ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ ÑÐ»Ð¾Ñ.
    
    Args:
        model: Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        input_size: ÐÐ¾Ð²Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð²Ñ…Ð¾Ð´Ð° (W, H, D)
        model_depth: Ð“Ð»ÑƒÐ±Ð¸Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸ ResNet
        n_seg_classes: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ»Ð°ÑÑÐ¾Ð²
    
    Returns:
        model: ÐÐ´Ð°Ð¿Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        trainable_parameters: ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
    """
    import torch
    import torch.nn as nn
    
    print(f"ÐÐ´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ð²Ñ…Ð¾Ð´Ð° Ñ€Ð°Ð·Ð¼ÐµÑ€Ð¾Ð¼ {input_size}...")
    
    # --- Ð—Ð°Ð¼Ð¾Ñ€Ð¾Ð·ÐºÐ° Ð²ÑÐµÑ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² ---
    print("Ð—Ð°Ð¼Ð¾Ñ€Ð°Ð¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð²ÑÐµÑ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²...")
    for param in model.parameters():
        param.requires_grad = False
    
    # --- Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ð¿Ð¾Ð»Ð½Ð¾ÑÐ²ÑÐ·Ð½Ð¾Ð³Ð¾ ÑÐ»Ð¾Ñ ---
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ„Ð¸ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ‚ÐµÐ½Ð·Ð¾Ñ€ Ð´Ð»Ñ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ñ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ð¿Ð¾ÑÐ»Ðµ ÑÐ²ÐµÑ€Ñ‚Ð¾Ðº
    with torch.no_grad():
        dummy_input = torch.randn(1, 1, input_size[2], input_size[1], input_size[0])
        
        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÐ²ÐµÑ€Ñ‚Ð¾Ñ‡Ð½ÑƒÑŽ Ñ‡Ð°ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        if hasattr(model, 'module'):
            # Ð•ÑÐ»Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¾Ð±ÐµÑ€Ð½ÑƒÑ‚Ð° Ð² DataParallel
            conv_features = nn.Sequential(
                model.module.conv1,
                model.module.bn1,
                model.module.relu,
                model.module.maxpool,
                model.module.layer1,
                model.module.layer2,
                model.module.layer3,
                model.module.layer4,
                model.module.avgpool
            )
        else:
            conv_features = nn.Sequential(
                model.conv1,
                model.bn1,
                model.relu,
                model.maxpool,
                model.layer1,
                model.layer2,
                model.layer3,
                model.layer4,
                model.avgpool
            )
        
        # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¿Ð¾ÑÐ»Ðµ ÑÐ²ÐµÑ€Ñ‚Ð¾Ñ‡Ð½Ñ‹Ñ… ÑÐ»Ð¾ÐµÐ²
        conv_output = conv_features(dummy_input)
        flattened_size = conv_output.view(conv_output.size(0), -1).size(1)
    
    print(f"ÐÐ¾Ð²Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð²Ñ…Ð¾Ð´Ð° FC ÑÐ»Ð¾Ñ: {flattened_size}")
    
    # --- Ð—Ð°Ð¼ÐµÐ½Ð° Ð¿Ð¾Ð»Ð½Ð¾ÑÐ²ÑÐ·Ð½Ð¾Ð³Ð¾ ÑÐ»Ð¾Ñ ---
    if hasattr(model, 'module'):
        # DataParallel ÑÐ»ÑƒÑ‡Ð°Ð¹
        old_fc = model.module.fc
        model.module.fc = nn.Linear(flattened_size, n_seg_classes)
        new_fc = model.module.fc
    else:
        old_fc = model.fc
        model.fc = nn.Linear(flattened_size, n_seg_classes)
        new_fc = model.fc
    
    print(f"Ð—Ð°Ð¼ÐµÐ½ÐµÐ½ FC ÑÐ»Ð¾Ð¹: {old_fc.in_features} â†’ {flattened_size} Ð²Ñ…Ð¾Ð´Ð¾Ð², {n_seg_classes} Ð²Ñ‹Ñ…Ð¾Ð´Ð¾Ð²")
    
    # --- Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð¾Ð²Ð¾Ð³Ð¾ ÑÐ»Ð¾Ñ ---
    if isinstance(new_fc, nn.Linear):
        # Xavier Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
        nn.init.xavier_uniform_(new_fc.weight)
        if new_fc.bias is not None:
            nn.init.zeros_(new_fc.bias)
    
    # --- Ð Ð°Ð·Ð¼Ð¾Ñ€Ð°Ð¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ FC ÑÐ»Ð¾Ñ ---
    print("Ð Ð°Ð·Ð¼Ð¾Ñ€Ð°Ð¶Ð¸Ð²Ð°Ð½Ð¸Ðµ FC ÑÐ»Ð¾Ñ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ...")
    for param in new_fc.parameters():
        param.requires_grad = True
    
    # --- Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼Ñ‹Ñ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² ---
    trainable_parameters = filter(lambda p: p.requires_grad, model.parameters())
    
    return model, trainable_parameters


def test_inference_example():
    """ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ inference."""
    rprint("\nðŸ”¬ [bold blue]Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ inference Ð¼Ð¾Ð´ÑƒÐ»Ñ...[/bold blue]")

    try:
        # Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ñ‚ÐµÐ½Ð·Ð¾Ñ€
        test_tensor = torch.randn(1, 1, 128, 128, 128)
        rprint(f"ðŸ“Š Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ñ‚ÐµÐ½Ð·Ð¾Ñ€: {test_tensor.shape}")

        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ inference Ð¾Ð±ÑŠÐµÐºÑ‚Ð°
        inference = MedicalModelInference(
            weights_path="model/outputs/checkpoints/best_weights.pth",
            model_config=ModelConfig()
        )

        # ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
        prediction = inference.predict(test_tensor)
        rprint(f"ðŸŽ¯ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ: {prediction}")

        # Ð‘Ð°Ñ‚Ñ‡ÐµÐ²Ð¾Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
        batch_tensor = torch.randn(3, 1, 128, 128, 128)
        batch_predictions = inference.predict_batch(batch_tensor)
        rprint(f"ðŸ“¦ ÐŸÐ°ÐºÐµÑ‚Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ: {batch_predictions}")

        rprint("âœ… [bold green]Inference Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾![/bold green]")

    except Exception as e:
        rprint(f"âŒ [bold red]ÐžÑˆÐ¸Ð±ÐºÐ° inference Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ:[/bold red] {str(e)}")


if __name__ == '__main__':
    if len(sys.argv) > 1 and sys.argv[1] == "--test-inference":
        test_inference_example()
    else:
        main()