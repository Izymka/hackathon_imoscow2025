# main.py
from datasets.medical_tensors import MedicalTensorDataset
from model_generator import generate_model
from lightning_module import MedicalClassificationModel
from torch.utils.data import DataLoader
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor
from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger
from config import ModelConfig
from omegaconf import OmegaConf
import torch
import argparse

# === –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º MONAI –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ===
from monai.transforms import Compose, RandFlip, RandRotate90, RandGaussianNoise

# === –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º inference –∫–ª–∞—Å—Å ===
from inference import MedicalModelInference


def get_train_transforms():
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏."""
    return Compose([
        RandFlip(prob=0.5, spatial_axis=0),
        RandRotate90(prob=0.5, max_k=1, spatial_axes=(1, 2)),
        RandGaussianNoise(prob=0.25, std=0.01),
    ])


def get_val_transforms():
    """–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–æ–±—ã—á–Ω–æ –Ω–µ—Ç)."""
    return None


def main():
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    cfg = ModelConfig()
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ OmegaConf
    cfg = OmegaConf.structured(cfg)

    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ CLI
    cli_cfg = OmegaConf.from_cli()
    cfg = OmegaConf.merge(cfg, cli_cfg)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ ci_test –∫–∞–∫ —Ä–∞–Ω—å—à–µ
    if cfg.ci_test:
        cfg.img_list = '../toy_data/test_ci.txt'
        cfg.n_epochs = 1
        cfg.no_cuda = True
        cfg.data_root = '../toy_data'
        cfg.pretrain_path = ''
        cfg.num_workers = 4
        cfg.model_depth = 10
        cfg.resnet_shortcut = 'A'
        cfg.input_D = 14
        cfg.input_H = 28
        cfg.input_W = 28
        cfg.batch_size = 2

    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed
    torch.manual_seed(cfg.manual_seed)

    # –°–æ–∑–¥–∞–µ–º namespace –æ–±—ä–µ–∫—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    cfg_dict = OmegaConf.to_container(cfg)

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∞—Ç—Ä–∏–±—É—Ç—ã
    cfg_dict['gpu_id'] = [] if cfg.no_cuda else [0]
    cfg_dict['phase'] = 'train'
    cfg_dict['pin_memory'] = not cfg.no_cuda

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º argparse.Namespace
    cfg_namespace = argparse.Namespace(**cfg_dict)

    # –£–°–¢–ê–ù–û–í–ò–¢–¨ –ù–ï–î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–û–°–¢–¨ –ü–ï–†–ï–î –°–û–ó–î–ê–ù–ò–ï–ú –ú–û–î–ï–õ–ò
    torch.use_deterministic_algorithms(False)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π —Ä–∞–∑–º–µ—Ä–∞ –≤—Ö–æ–¥–∞
    model, parameters = generate_model(cfg_namespace)
    
    # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
    print(f"–ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ –¥–ª—è –≤—Ö–æ–¥–∞ —Ä–∞–∑–º–µ—Ä–æ–º: {cfg.input_W}√ó{cfg.input_H}√ó{cfg.input_D}")
    if hasattr(cfg_namespace, 'pretrain_path') and cfg_namespace.pretrain_path:
        print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å —Ä–∞–∑–º–µ—Ä–æ–º –≤—Ö–æ–¥–∞: {cfg.pretrain_input_size}√ó{cfg.pretrain_input_size}√ó{cfg.pretrain_input_size}")
    
    lightning_model = MedicalClassificationModel(
        model,
        learning_rate=cfg.learning_rate,
    )

    # === –°–æ–∑–¥–∞–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ===
    train_transforms = get_train_transforms()
    val_transforms = get_val_transforms()

    # === –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏ ===
    train_dataset = MedicalTensorDataset(
        cfg.data_root,
        cfg.img_list,
        cfg_namespace,
        transform=train_transforms  # <-- –¥–æ–±–∞–≤–ª—è–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
    )

    # –£–º–µ–Ω—å—à–∞–µ–º num_workers –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å pickle
    num_workers = 0 if cfg.ci_test else 4  # –≤—Ä–µ–º–µ–Ω–Ω–æ 0 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg.batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=cfg_namespace.pin_memory,
        persistent_workers=num_workers > 0
    )

    val_dataset = MedicalTensorDataset(
        cfg.val_data_root,
        cfg.val_list,
        cfg_namespace,
        transform=val_transforms  # <-- –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=cfg_namespace.pin_memory,
        persistent_workers=num_workers > 0
    )

    # Logger & Checkpointing
    tb_logger = TensorBoardLogger("tb_logs", name="medical_classification")
    csv_logger = CSVLogger("logs", name="medical_classification")

    # Callback –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–∏—Ö –≤–µ—Å–æ–≤
    best_model_checkpoint = ModelCheckpoint(
        dirpath=cfg.save_folder,
        filename="best-checkpoint-{epoch:02d}-{val_acc:.3f}-{val_f1:.3f}",
        save_top_k=cfg.save_top_k,
        monitor=cfg.monitor_metric,
        mode=cfg.checkpoint_mode,
        save_weights_only=True,
        verbose=True
    )

    # Callback –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
    last_model_checkpoint = ModelCheckpoint(
        dirpath=cfg.save_folder,
        filename="last-checkpoint-{epoch:02d}-{val_acc:.3f}-{val_f1:.3f}",
        save_top_k=1,
        monitor=None,
        save_weights_only=True,
        verbose=True
    )

    # Callback –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    early_stopping = EarlyStopping(
        monitor=cfg.early_stopping_metric,
        min_delta=cfg.early_stopping_min_delta,
        patience=cfg.early_stopping_patience,
        verbose=True,
        mode=cfg.checkpoint_mode
    )

    # Callback –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ learning rate
    lr_monitor = LearningRateMonitor(logging_interval='epoch')

    # Trainer - –ø—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º accelerator –∏ devices
    if cfg.no_cuda or not torch.cuda.is_available():
        accelerator = "cpu"
        devices = 1
    else:
        accelerator = "gpu"
        devices = 1

    trainer = pl.Trainer(
        max_epochs=cfg.n_epochs,
        logger=[tb_logger, csv_logger],
        callbacks=[best_model_checkpoint, last_model_checkpoint, early_stopping, lr_monitor],
        accelerator=accelerator,
        devices=devices,
        fast_dev_run=cfg.ci_test,
        log_every_n_steps=1,
        enable_progress_bar=True,
        enable_model_summary=True,
        # deterministic=cfg.deterministic,  # –ü–û–õ–ù–û–°–¢–¨–Æ –£–ë–†–ê–¢–¨ –≠–¢–£ –°–¢–†–û–ö–£
        gradient_clip_val=cfg.gradient_clip_val,
    )

    # Train
    trainer.fit(
        lightning_model,
        train_dataloaders=train_loader,
        val_dataloaders=val_loader
    )

    # –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞
    best_checkpoint_path = best_model_checkpoint.best_model_path
    if best_checkpoint_path:
        print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏–∑: {best_checkpoint_path}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –≤–µ—Å–∞–º–∏
        best_model = MedicalClassificationModel.load_from_checkpoint(
            best_checkpoint_path,
            model=model,
            learning_rate=cfg.learning_rate
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ (state_dict)
        torch.save(best_model.model.state_dict(), f"{cfg.save_folder}/best_weights.pth")
        print(f"–õ—É—á—à–∏–µ –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {cfg.save_folder}/best_weights.pth")


def test_inference_example():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è inference –∫–ª–∞—Å—Å–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("\nüî¨ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ inference –∫–ª–∞—Å—Å–∞...")

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä
    test_tensor = torch.randn(1, 1, 128, 128, 128)
    print(f"–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä: {test_tensor.shape}")

    # –°–æ–∑–¥–∞–µ–º inference –æ–±—ä–µ–∫—Ç
    inference = MedicalModelInference(
        weights_path="model/outputs/checkpoints/best_weights.pth",
        model_config=ModelConfig()
    )

    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    prediction = inference.predict(test_tensor)
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {prediction}")

    # –ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    batch_tensor = torch.randn(3, 1, 128, 128, 128)
    batch_predictions = inference.predict_batch(batch_tensor)
    print(f"–ü–∞–∫–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {batch_predictions}")


if __name__ == '__main__':
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "--test-inference":
        test_inference_example()
    else:
        main()