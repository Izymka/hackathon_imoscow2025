# main.py
import os
import sys
import argparse
import warnings
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import torch
import torch.nn.functional as F
import pytorch_lightning as pl
from torch.utils.data import DataLoader
from pytorch_lightning.callbacks import (
    ModelCheckpoint,
    EarlyStopping,
    LearningRateMonitor,
    RichProgressBar,
    RichModelSummary
)
from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger
from omegaconf import OmegaConf
from sklearn.model_selection import StratifiedKFold
import pandas as pd
import numpy as np
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich import print as rprint

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# === –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã ===
from datasets.medical_tensors import MedicalTensorDataset
from model_generator import generate_model
from lightning_module import MedicalClassificationModel
from config import ModelConfig
from inference import MedicalModelInference

# === MONAI –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ===
from monai.transforms import (
    Compose,
    RandFlip,
    RandRotate90,
    RandGaussianNoise,
    RandShiftIntensity,
    RandAdjustContrast,
    RandScaleIntensity,
    CropForeground,
    SpatialPad,
    EnsureChannelFirst,
    Orientation,
    ToTensor
)

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings("ignore", category=UserWarning)

console = Console()


def get_safe_train_transforms(input_size: Tuple[int, int, int]) -> Compose:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö 3D –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    –°–æ—Ö—Ä–∞–Ω—è—é—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö.
    """
    return Compose([
        #EnsureChannelFirst(),

        # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ)
        RandFlip(prob=0.3, spatial_axis=0),  # —Ç–æ–ª—å–∫–æ –ø–æ –æ–¥–Ω–æ–π –æ—Å–∏
        RandRotate90(prob=0.2, max_k=1, spatial_axes=(1, 2)),  # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–∞—â–µ–Ω–∏–µ

        # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–Ω—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (—Å–ª–∞–±—ã–µ)
        RandGaussianNoise(prob=0.15, std=0.005),  # –æ—á–µ–Ω—å —Å–ª–∞–±—ã–π —à—É–º
        RandShiftIntensity(offsets=0.05, prob=0.2),  # —Å–¥–≤–∏–≥ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏
        RandAdjustContrast(gamma=(0.9, 1.1), prob=0.2),  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        RandScaleIntensity(factors=(-0.05, 0.05), prob=0.2),  # –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

        #ToTensor(),
    ])


def get_val_transforms() -> Compose:
    """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)."""
    return Compose([
        #EnsureChannelFirst(),
        #ToTensor(),
    ])


class CrossValidationTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏."""

    def __init__(self, cfg: OmegaConf, cfg_namespace: argparse.Namespace):
        self.cfg = cfg
        self.cfg_namespace = cfg_namespace
        self.results = []

    def load_data_labels(self) -> Tuple[List[str], List[int]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –∏ –º–µ—Ç–∫–∏ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏."""
        labels_df = pd.read_csv(self.cfg.img_list)

        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ CSV: filename, label
        if 'filename' not in labels_df.columns or 'label' not in labels_df.columns:
            raise ValueError("CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'filename' –∏ 'label'")

        filenames = labels_df['filename'].tolist()
        labels = labels_df['label'].tolist()

        return filenames, labels

    def create_fold_datasets(self, train_indices: List[int], val_indices: List[int],
                             filenames: List[str], labels: List[int]) -> Tuple[DataLoader, DataLoader]:
        """–°–æ–∑–¥–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç—ã –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–ª—è —Ñ–æ–ª–¥–∞."""

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ CSV —Ñ–∞–π–ª—ã –¥–ª—è —Ñ–æ–ª–¥–∞
        train_data = [(filenames[i], labels[i]) for i in train_indices]
        val_data = [(filenames[i], labels[i]) for i in val_indices]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        train_df = pd.DataFrame(train_data, columns=['filename', 'label'])
        val_df = pd.DataFrame(val_data, columns=['filename', 'label'])

        fold_train_path = f"temp_train_fold.csv"
        fold_val_path = f"temp_val_fold.csv"

        train_df.to_csv(fold_train_path, index=False)
        val_df.to_csv(fold_val_path, index=False)

        # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
        train_dataset = MedicalTensorDataset(
            self.cfg.data_root,
            fold_train_path,
            self.cfg_namespace,
            transform=get_safe_train_transforms((self.cfg.input_D, self.cfg.input_H, self.cfg.input_W))
        )

        val_dataset = MedicalTensorDataset(
            self.cfg.data_root,
            fold_val_path,
            self.cfg_namespace,
            transform=get_val_transforms()
        )

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã DataLoader
        num_workers = 0 if self.cfg.ci_test else min(0, os.cpu_count())

        train_loader = DataLoader(
            train_dataset,
            batch_size=self.cfg.batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=self.cfg_namespace.pin_memory and torch.cuda.is_available(),
            persistent_workers=num_workers > 0,
            drop_last=True
        )

        val_loader = DataLoader(
            val_dataset,
            batch_size=self.cfg.batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=self.cfg_namespace.pin_memory and torch.cuda.is_available(),
            persistent_workers=num_workers > 0
        )

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        os.remove(fold_train_path)
        os.remove(fold_val_path)

        return train_loader, val_loader

    def train_fold(self, fold: int, train_loader: DataLoader, val_loader: DataLoader) -> Dict:
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –æ–¥–Ω–æ–º —Ñ–æ–ª–¥–µ."""

        rprint(f"\nüìÑ [bold blue]–û–±—É—á–µ–Ω–∏–µ —Ñ–æ–ª–¥–∞ {fold + 1}/{self.cfg.n_splits}[/bold blue]")

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Ñ–æ–ª–¥–∞
        model, parameters = generate_model(self.cfg_namespace)

        # –ù–ï –ø–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –≤—Ä—É—á–Ω—É—é - Lightning —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        device_name = 'GPU' if torch.cuda.is_available() and not self.cfg.no_cuda else 'CPU'
        print(f"‚úÖ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {device_name}")

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ CPU
        class_weights = self.calculate_class_weights(train_loader)

        lightning_model = MedicalClassificationModel(
            model,
            learning_rate=self.cfg.learning_rate,
            num_classes=self.cfg.n_seg_classes,
            use_weighted_loss=True,
            class_weights=class_weights  # Lightning –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        )

        # –õ–æ–≥–≥–µ—Ä—ã –¥–ª—è —Ñ–æ–ª–¥–∞
        fold_name = f"medical_classification_fold_{fold + 1}"
        tb_logger = TensorBoardLogger("tb_logs", name=fold_name, version=f"fold_{fold + 1}")
        csv_logger = CSVLogger("logs", name=fold_name, version=f"fold_{fold + 1}")

        # –ö–æ–ª–ª–±—ç–∫–∏
        checkpoint_callback = ModelCheckpoint(
            dirpath=f"{self.cfg.save_folder}/fold_{fold + 1}",
            filename="best-{epoch:02d}-{val_f1:.4f}-{val_auroc:.4f}",
            save_top_k=2,
            monitor=self.cfg.monitor_metric,
            mode=self.cfg.checkpoint_mode,
            save_weights_only=False,
            verbose=False
        )

        early_stopping = EarlyStopping(
            monitor=self.cfg.early_stopping_metric,
            min_delta=self.cfg.early_stopping_min_delta,
            patience=self.cfg.early_stopping_patience,
            verbose=False,
            mode=self.cfg.checkpoint_mode
        )

        lr_monitor = LearningRateMonitor(logging_interval='epoch')

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ accelerator
        if self.cfg.no_cuda or not torch.cuda.is_available():
            accelerator = "cpu"
            devices = 1
        else:
            accelerator = "gpu"
            devices = 1

        # –°–æ–∑–¥–∞–µ–º trainer
        trainer = pl.Trainer(
            max_epochs=self.cfg.n_epochs,
            logger=[tb_logger, csv_logger],
            callbacks=[
                checkpoint_callback,
                early_stopping,
                lr_monitor,
                RichProgressBar(),
            ],
            accelerator=accelerator,
            devices=devices,
            fast_dev_run=self.cfg.ci_test,
            log_every_n_steps=min(10, len(train_loader) // 4),
            enable_progress_bar=True,
            enable_model_summary=True,
            gradient_clip_val=self.cfg.gradient_clip_val,
            precision=16 if accelerator == "gpu" else 32,  # mixed precision
        )

        # –û–±—É—á–µ–Ω–∏–µ
        trainer.fit(lightning_model, train_loader, val_loader)

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        best_metrics = checkpoint_callback.best_model_score.item()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        best_model = MedicalClassificationModel.load_from_checkpoint(
            checkpoint_callback.best_model_path,
            model=model,
            learning_rate=self.cfg.learning_rate,
            num_classes=self.cfg.n_seg_classes
        )

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        trainer.validate(best_model, val_loader, verbose=False)

        fold_results = {
            'fold': fold + 1,
            'best_val_score': best_metrics,
            'best_checkpoint': checkpoint_callback.best_model_path,
            'final_epoch': trainer.current_epoch,
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if hasattr(best_model, 'validation_metrics'):
            fold_results.update(best_model.validation_metrics)

        return fold_results

    def calculate_class_weights(self, train_loader: DataLoader) -> torch.Tensor:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å."""
        class_counts = torch.zeros(self.cfg.n_seg_classes)

        for batch in train_loader:
            _, labels = batch
            for label in labels:
                class_counts[int(label.item())] += 1

        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã
        total_samples = class_counts.sum()
        class_weights = total_samples / (self.cfg.n_seg_classes * class_counts)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        class_weights = class_weights / class_weights.sum() * self.cfg.n_seg_classes

        return class_weights

    def run_cross_validation(self) -> Dict:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é."""

        # –ö—Ä–∞—Å–∏–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
        console.print(Panel.fit(
            "[bold green]üè• –ú–ï–î–ò–¶–ò–ù–°–ö–ê–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø - –ö–†–û–°–°-–í–ê–õ–ò–î–ê–¶–ò–Ø üè•[/bold green]",
            border_style="green"
        ))

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        filenames, labels = self.load_data_labels()

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
        unique_labels, counts = np.unique(labels, return_counts=True)

        data_table = Table(title="üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
        data_table.add_column("–ü–∞—Ä–∞–º–µ—Ç—Ä", style="cyan")
        data_table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="yellow")

        data_table.add_row("–í—Å–µ–≥–æ –æ–±—Ä–∞–∑—Ü–æ–≤", str(len(filenames)))
        for label, count in zip(unique_labels, counts):
            data_table.add_row(f"–ö–ª–∞—Å—Å {label}", f"{count} ({count / len(labels) * 100:.1f}%)")

        console.print(data_table)

        # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        skf = StratifiedKFold(
            n_splits=self.cfg.n_splits,
            shuffle=True,
            random_state=self.cfg.cv_random_state
        )

        all_results = []

        # –û–±—É—á–µ–Ω–∏–µ –ø–æ —Ñ–æ–ª–¥–∞–º
        for fold, (train_indices, val_indices) in enumerate(skf.split(filenames, labels)):
            # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è —Ñ–æ–ª–¥–∞
            train_loader, val_loader = self.create_fold_datasets(
                train_indices, val_indices, filenames, labels
            )

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–æ–ª–¥–µ
            train_labels = [labels[i] for i in train_indices]
            val_labels = [labels[i] for i in val_indices]

            fold_table = Table(title=f"üìã –§–æ–ª–¥ {fold + 1}")
            fold_table.add_column("–ù–∞–±–æ—Ä", style="cyan")
            fold_table.add_column("–†–∞–∑–º–µ—Ä", style="yellow")
            fold_table.add_column("–ö–ª–∞—Å—Å 0", style="red")
            fold_table.add_column("–ö–ª–∞—Å—Å 1", style="green")

            train_counts = np.bincount(train_labels)
            val_counts = np.bincount(val_labels)

            fold_table.add_row(
                "–û–±—É—á–µ–Ω–∏–µ",
                str(len(train_indices)),
                f"{train_counts[0]} ({train_counts[0] / len(train_indices) * 100:.1f}%)",
                f"{train_counts[1]} ({train_counts[1] / len(train_indices) * 100:.1f}%)"
            )
            fold_table.add_row(
                "–í–∞–ª–∏–¥–∞—Ü–∏—è",
                str(len(val_indices)),
                f"{val_counts[0]} ({val_counts[0] / len(val_indices) * 100:.1f}%)",
                f"{val_counts[1]} ({val_counts[1] / len(val_indices) * 100:.1f}%)"
            )

            console.print(fold_table)

            # –û–±—É—á–µ–Ω–∏–µ —Ñ–æ–ª–¥–∞
            fold_results = self.train_fold(fold, train_loader, val_loader)
            all_results.append(fold_results)

            # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            rprint(f"‚úÖ [bold green]–§–æ–ª–¥ {fold + 1} –∑–∞–≤–µ—Ä—à–µ–Ω![/bold green]")
            rprint(f"   üìà –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {fold_results['best_val_score']:.4f}")

        # –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º —Ñ–æ–ª–¥–∞–º
        self.print_cv_summary(all_results)

        return {
            'fold_results': all_results,
            'cv_summary': self.calculate_cv_summary(all_results)
        }

    def calculate_cv_summary(self, results: List[Dict]) -> Dict:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏."""
        scores = [r['best_val_score'] for r in results]

        return {
            'mean_score': np.mean(scores),
            'std_score': np.std(scores),
            'min_score': np.min(scores),
            'max_score': np.max(scores),
            'median_score': np.median(scores)
        }

    def print_cv_summary(self, results: List[Dict]):
        """–í—ã–≤–æ–¥–∏—Ç –∫—Ä–∞—Å–∏–≤—É—é —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏."""

        summary_table = Table(title="üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–†–û–°–°-–í–ê–õ–ò–î–ê–¶–ò–ò")
        summary_table.add_column("–§–æ–ª–¥", style="cyan", justify="center")
        summary_table.add_column("–õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç", style="yellow", justify="center")
        summary_table.add_column("–§–∏–Ω–∞–ª—å–Ω–∞—è —ç–ø–æ—Ö–∞", style="blue", justify="center")

        scores = []
        for result in results:
            summary_table.add_row(
                str(result['fold']),
                f"{result['best_val_score']:.4f}",
                str(result['final_epoch'])
            )
            scores.append(result['best_val_score'])

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        summary_table.add_row("---", "---", "---", style="dim")
        summary_table.add_row(
            "–°–†–ï–î–ù–ï–ï",
            f"{np.mean(scores):.4f} ¬± {np.std(scores):.4f}",
            "",
            style="bold green"
        )

        console.print(summary_table)

        # –ü–∞–Ω–µ–ª—å —Å –∏—Ç–æ–≥–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        summary_text = f"""
[bold green]üìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:[/bold green]
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {np.mean(scores):.4f} ¬± {np.std(scores):.4f}
‚Ä¢ –õ—É—á—à–∏–π —Ñ–æ–ª–¥: {np.max(scores):.4f}
‚Ä¢ –•—É–¥—à–∏–π —Ñ–æ–ª–¥: {np.min(scores):.4f}
‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞: {np.median(scores):.4f}
‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏: {(np.std(scores) / np.mean(scores) * 100):.2f}%
        """

        console.print(Panel(summary_text, title="üèÜ –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç", border_style="green"))


def setup_environment(cfg: OmegaConf) -> argparse.Namespace:
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."""

    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    torch.manual_seed(cfg.manual_seed)
    np.random.seed(cfg.manual_seed)

    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    Path(cfg.save_folder).mkdir(parents=True, exist_ok=True)
    Path("tb_logs").mkdir(exist_ok=True)
    Path("logs").mkdir(exist_ok=True)

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ namespace
    cfg_dict = OmegaConf.to_container(cfg)
    cfg_dict['gpu_id'] = [] if cfg.no_cuda else [0]
    cfg_dict['phase'] = 'train'
    cfg_dict['pin_memory'] = not cfg.no_cuda and torch.cuda.is_available()

    # –û—Ç–∫–ª—é—á–∞–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    torch.use_deterministic_algorithms(False)

    return argparse.Namespace(**cfg_dict)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è."""

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞
        cfg = ModelConfig()
        cfg = OmegaConf.structured(cfg)

        # CLI –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        cli_cfg = OmegaConf.from_cli()
        cfg = OmegaConf.merge(cfg, cli_cfg)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è CI —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if cfg.ci_test:
            cfg.img_list = '../toy_data/test_ci.txt'
            cfg.n_epochs = 2
            cfg.no_cuda = True
            cfg.data_root = '../toy_data'
            cfg.pretrain_path = ''
            cfg.num_workers = 0
            cfg.batch_size = 2
            cfg.n_splits = 2

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        cfg_namespace = setup_environment(cfg)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
        device_info = "CPU" if cfg.no_cuda else f"GPU ({torch.cuda.get_device_name()})" if torch.cuda.is_available() else "CPU (CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)"

        system_table = Table(title="üíª –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ")
        system_table.add_column("–ü–∞—Ä–∞–º–µ—Ç—Ä", style="cyan")
        system_table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="yellow")

        system_table.add_row("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ", device_info)
        system_table.add_row("PyTorch –≤–µ—Ä—Å–∏—è", torch.__version__)
        system_table.add_row("CUDA –¥–æ—Å—Ç—É–ø–Ω–∞", str(torch.cuda.is_available()))
        system_table.add_row("–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞", str(cfg.batch_size))
        system_table.add_row("Learning rate", str(cfg.learning_rate))
        system_table.add_row("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤", str(cfg.n_splits))
        system_table.add_row("–ú–∞–∫—Å–∏–º—É–º —ç–ø–æ—Ö", str(cfg.n_epochs))

        console.print(system_table)

        # –ó–∞–ø—É—Å–∫ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
        cv_trainer = CrossValidationTrainer(cfg, cfg_namespace)
        results = cv_trainer.run_cross_validation()

        rprint("\nüéâ [bold green]–û–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ![/bold green]")

        return results

    except Exception as e:
        rprint(f"\n‚ùå [bold red]–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:[/bold red] {str(e)}")
        console.print_exception(show_locals=True)
        return None


def adapt_model_for_input_size(model, input_size, model_depth, n_seg_classes):
    """
    –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –≤—Ö–æ–¥–∞ –ø—É—Ç–µ–º –∑–∞–º–µ–Ω—ã –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è.
    
    Args:
        model: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        input_size: –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ (W, H, D)
        model_depth: –ì–ª—É–±–∏–Ω–∞ –º–æ–¥–µ–ª–∏ ResNet
        n_seg_classes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
    
    Returns:
        model: –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        trainable_parameters: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    """
    import torch
    import torch.nn as nn
    
    print(f"–ê–¥–∞–ø—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Ö–æ–¥–∞ —Ä–∞–∑–º–µ—Ä–æ–º {input_size}...")
    
    # --- –ó–∞–º–æ—Ä–æ–∑–∫–∞ –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ---
    print("–ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
    for param in model.parameters():
        param.requires_grad = False
    
    # --- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è ---
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–æ–∫
    with torch.no_grad():
        dummy_input = torch.randn(1, 1, input_size[2], input_size[1], input_size[0])
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–≤–µ—Ä—Ç–æ—á–Ω—É—é —á–∞—Å—Ç—å –º–æ–¥–µ–ª–∏
        if hasattr(model, 'module'):
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –æ–±–µ—Ä–Ω—É—Ç–∞ –≤ DataParallel
            conv_features = nn.Sequential(
                model.module.conv1,
                model.module.bn1,
                model.module.relu,
                model.module.maxpool,
                model.module.layer1,
                model.module.layer2,
                model.module.layer3,
                model.module.layer4,
                model.module.avgpool
            )
        else:
            conv_features = nn.Sequential(
                model.conv1,
                model.bn1,
                model.relu,
                model.maxpool,
                model.layer1,
                model.layer2,
                model.layer3,
                model.layer4,
                model.avgpool
            )
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤
        conv_output = conv_features(dummy_input)
        flattened_size = conv_output.view(conv_output.size(0), -1).size(1)
    
    print(f"–ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ FC —Å–ª–æ—è: {flattened_size}")
    
    # --- –ó–∞–º–µ–Ω–∞ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è ---
    if hasattr(model, 'module'):
        # DataParallel —Å–ª—É—á–∞–π
        old_fc = model.module.fc
        model.module.fc = nn.Linear(flattened_size, n_seg_classes)
        new_fc = model.module.fc
    else:
        old_fc = model.fc
        model.fc = nn.Linear(flattened_size, n_seg_classes)
        new_fc = model.fc
    
    print(f"–ó–∞–º–µ–Ω–µ–Ω FC —Å–ª–æ–π: {old_fc.in_features} ‚Üí {flattened_size} –≤—Ö–æ–¥–æ–≤, {n_seg_classes} –≤—ã—Ö–æ–¥–æ–≤")
    
    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ —Å–ª–æ—è ---
    if isinstance(new_fc, nn.Linear):
        # Xavier –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        nn.init.xavier_uniform_(new_fc.weight)
        if new_fc.bias is not None:
            nn.init.zeros_(new_fc.bias)
    
    # --- –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ FC —Å–ª–æ—è ---
    print("–†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ FC —Å–ª–æ—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
    for param in new_fc.parameters():
        param.requires_grad = True
    
    # --- –í–æ–∑–≤—Ä–∞—Ç –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ---
    trainable_parameters = filter(lambda p: p.requires_grad, model.parameters())
    
    return model, trainable_parameters


def test_inference_example():
    """–ü—Ä–∏–º–µ—Ä —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è inference."""
    rprint("\nüî¨ [bold blue]–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ inference –º–æ–¥—É–ª—è...[/bold blue]")

    try:
        # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä
        test_tensor = torch.randn(1, 1, 128, 128, 128)
        rprint(f"üìä –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä: {test_tensor.shape}")

        # –°–æ–∑–¥–∞–Ω–∏–µ inference –æ–±—ä–µ–∫—Ç–∞
        inference = MedicalModelInference(
            weights_path="model/outputs/checkpoints/best_weights.pth",
            model_config=ModelConfig()
        )

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction = inference.predict(test_tensor)
        rprint(f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {prediction}")

        # –ë–∞—Ç—á–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        batch_tensor = torch.randn(3, 1, 128, 128, 128)
        batch_predictions = inference.predict_batch(batch_tensor)
        rprint(f"üì¶ –ü–∞–∫–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {batch_predictions}")

        rprint("‚úÖ [bold green]Inference —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ![/bold green]")

    except Exception as e:
        rprint(f"‚ùå [bold red]–û—à–∏–±–∫–∞ inference —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:[/bold red] {str(e)}")


if __name__ == '__main__':
    if len(sys.argv) > 1 and sys.argv[1] == "--test-inference":
        test_inference_example()
    else:
        main()